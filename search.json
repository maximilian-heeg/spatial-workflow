[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Some information here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spatial workflow",
    "section": "",
    "text": "Welcome to our website, where we aim to provide a overview of our workflow to analyze spatial transcriptomics. Please be aware that this website is still under construction, and we make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability or availability of the information provided here."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Spatial workflow",
    "section": "Getting started",
    "text": "Getting started\nRead about our approaches for cell segmentation here"
  },
  {
    "objectID": "workflow/cell_segmentation/baysor/script.html",
    "href": "workflow/cell_segmentation/baysor/script.html",
    "title": "Script",
    "section": "",
    "text": "#!/bin/bash\n#PBS -q home-yeo\n#PBS -N baysor\n#PBS -l nodes=1:ppn=8\n#PBS -l walltime=48:00:00\n#PBS -l pmem=120gb\n#PBS -o baysor.log\n#PBS -e baysor.err\n#PBS -m abe\n#PBS -M mheeg@ucsd.edu\n\n# use with qsub -v mol=30\n\ncd /home/mheeg/projects/Merscope/Slide_01/202206_Duodenum_day_7/cell_segmentation/\n\n\nmkdir -p baysor_30_mol_per_cell\n\n/home/mheeg/bin/Baysor/bin/Baysor run -g gene -x global_x -y global_y \\\n    -z global_z -o baysor_30_mol_per_cell -p \\\n    -m 30 \\\n    --n-clusters 8 \\\n    --save-polygons=geojson \\\n    -s 5.0 --scale-std=50% \\\n    --prior-segmentation-confidence 0.7 \\\n    cellpose_segmentation/transcripts.csv :mask"
  },
  {
    "objectID": "workflow/cell_segmentation/baysor/index.html",
    "href": "workflow/cell_segmentation/baysor/index.html",
    "title": "Baysor",
    "section": "",
    "text": "Petukhov et al. (2022)\n\n\n\n\n\n\n\n\n\n\n\nScript\n\n\n\n\n\nRun Baysor on the TSCC\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\nNo matching items\n\nReferences\n\nPetukhov, Viktor, Rosalind J. Xu, Ruslan A. Soldatov, Paolo Cadinu, Konstantin Khodosevich, Jeffrey R. Moffitt, and Peter V. Kharchenko. 2022. “Cell segmentation in imaging-based spatial transcriptomics.” Nature Biotechnology 40 (3): 345–54. https://doi.org/10.1038/s41587-021-01044-w."
  },
  {
    "objectID": "workflow/cell_segmentation/cellpose/create_stack.html",
    "href": "workflow/cell_segmentation/cellpose/create_stack.html",
    "title": "Prepare the images",
    "section": "",
    "text": "import glob\nimport tifffile\nimport numpy as np\nfrom skimage.transform import resize\n\n\ndef import_layer(layer, scale=10, verbose=False):\n    \"\"\" Import all images from that layer and stack them\n    \n    Parameters\n    --------------\n    layer: name of the layer, e.g. pyrmosaic_PolyT\n    scale: factor by which the image should be resized\n    \n    Returns\n    --------------\n    A np array of shape (Z x Y x X)\n    \n    \"\"\"\n    \n    if verbose: print(f\"Import layers for \\\"{layer}\\\"\")\n    # get all files that match the pattern\n    files = glob.glob(\"../raw_data/pictures/\" + layer + \"_z[0-9].tif\")\n    files.sort()\n    # import the files and subset, scale=10 -> at 10th of the initial size\n    imgs = []\n    for f in files:\n        if verbose: print(f\"... Reading \\\"{f}\\\"\")\n        img = tifffile.imread(f)\n        if scale > 1:\n            # s = np.array(img.shape)\n            # if verbose: print(f\"... ... initial size {s}\")\n            # s = np.round(s / scale) \n            # if verbose: print(f\"... ... new size {s}\")\n            # img = resize(img, s).astype(np.int8)\n            # if verbose: print(f\"... ... done {s}\")\n            img = img[::scale, ::scale].copy()\n        imgs.append(img)\n    if verbose: print(f\"... stacking\")\n    imgs = np.stack(imgs, axis=0)\n    return imgs\n\n\npolyT = import_layer(\"pyrmosaic_PolyT\", scale=3, verbose=True)\ncell2 = import_layer(\"pyrmosaic_Cellbound2\", scale=3, verbose=True)\n\nShaped series: series shape does not match page shape\n\n\nImporint layres for \"pyrmosaic_PolyT\"\n... Reading \"../raw_data/pictures/pyrmosaic_PolyT_z0.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_PolyT_z1.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_PolyT_z2.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_PolyT_z3.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_PolyT_z4.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_PolyT_z5.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_PolyT_z6.tif\"\n... stacking\n\n\nShaped series: series shape does not match page shape\n\n\nImporint layres for \"pyrmosaic_Cellbound2\"\n... Reading \"../raw_data/pictures/pyrmosaic_Cellbound2_z0.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_Cellbound2_z1.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_Cellbound2_z2.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_Cellbound2_z3.tif\"\n... Reading \"../raw_data/pictures/pyrmosaic_Cellbound2_z4.tif\"\n\n\nShaped series: series shape does not match page shape\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_Cellbound2_z5.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\n... Reading \"../raw_data/pictures/pyrmosaic_Cellbound2_z6.tif\"\n... stacking\n\n\n\nstack = np.stack([cell2, polyT], 1)\n\n\nwith tifffile.TiffWriter('scratch/full_stack.tif',  bigtiff=True) as tif:\n    tif.save(stack)\n\n\ndef tile_img(img, tiles=2):\n    res = np.array_split(img, tiles, axis=2)\n    res = [np.array_split(t, tiles, axis=3) for t in res]\n\n    for x in range(len(res)):\n        for y in range(len(res[x])):\n            print(f\"Saving tile x:{x} y:{y}\")\n            with tifffile.TiffWriter(f\"scratch/tiles/tile_{x}_{y}.tif\") as tif:\n                tif.save(res[x][y])\n\n\ntile_img(stack, tiles=12)\n\nSaving tile x:0 y:0\nSaving tile x:0 y:1\nSaving tile x:0 y:2\nSaving tile x:0 y:3\nSaving tile x:0 y:4\nSaving tile x:0 y:5\nSaving tile x:0 y:6\nSaving tile x:0 y:7\nSaving tile x:0 y:8\nSaving tile x:0 y:9\nSaving tile x:0 y:10\nSaving tile x:0 y:11\nSaving tile x:1 y:0\nSaving tile x:1 y:1\nSaving tile x:1 y:2\nSaving tile x:1 y:3\nSaving tile x:1 y:4\nSaving tile x:1 y:5\nSaving tile x:1 y:6\nSaving tile x:1 y:7\nSaving tile x:1 y:8\nSaving tile x:1 y:9\nSaving tile x:1 y:10\nSaving tile x:1 y:11\nSaving tile x:2 y:0\nSaving tile x:2 y:1\nSaving tile x:2 y:2\nSaving tile x:2 y:3\nSaving tile x:2 y:4\nSaving tile x:2 y:5\nSaving tile x:2 y:6\nSaving tile x:2 y:7\nSaving tile x:2 y:8\nSaving tile x:2 y:9\nSaving tile x:2 y:10\nSaving tile x:2 y:11\nSaving tile x:3 y:0\nSaving tile x:3 y:1\nSaving tile x:3 y:2\nSaving tile x:3 y:3\nSaving tile x:3 y:4\nSaving tile x:3 y:5\nSaving tile x:3 y:6\nSaving tile x:3 y:7\nSaving tile x:3 y:8\nSaving tile x:3 y:9\nSaving tile x:3 y:10\nSaving tile x:3 y:11\nSaving tile x:4 y:0\nSaving tile x:4 y:1\nSaving tile x:4 y:2\nSaving tile x:4 y:3\nSaving tile x:4 y:4\nSaving tile x:4 y:5\nSaving tile x:4 y:6\nSaving tile x:4 y:7\nSaving tile x:4 y:8\nSaving tile x:4 y:9\nSaving tile x:4 y:10\nSaving tile x:4 y:11\nSaving tile x:5 y:0\nSaving tile x:5 y:1\nSaving tile x:5 y:2\nSaving tile x:5 y:3\nSaving tile x:5 y:4\nSaving tile x:5 y:5\nSaving tile x:5 y:6\nSaving tile x:5 y:7\nSaving tile x:5 y:8\nSaving tile x:5 y:9\nSaving tile x:5 y:10\nSaving tile x:5 y:11\nSaving tile x:6 y:0\nSaving tile x:6 y:1\nSaving tile x:6 y:2\nSaving tile x:6 y:3\nSaving tile x:6 y:4\nSaving tile x:6 y:5\nSaving tile x:6 y:6\nSaving tile x:6 y:7\nSaving tile x:6 y:8\nSaving tile x:6 y:9\nSaving tile x:6 y:10\nSaving tile x:6 y:11\nSaving tile x:7 y:0\nSaving tile x:7 y:1\nSaving tile x:7 y:2\nSaving tile x:7 y:3\nSaving tile x:7 y:4\nSaving tile x:7 y:5\nSaving tile x:7 y:6\nSaving tile x:7 y:7\nSaving tile x:7 y:8\nSaving tile x:7 y:9\nSaving tile x:7 y:10\nSaving tile x:7 y:11\nSaving tile x:8 y:0\nSaving tile x:8 y:1\nSaving tile x:8 y:2\nSaving tile x:8 y:3\nSaving tile x:8 y:4\nSaving tile x:8 y:5\nSaving tile x:8 y:6\nSaving tile x:8 y:7\nSaving tile x:8 y:8\nSaving tile x:8 y:9\nSaving tile x:8 y:10\nSaving tile x:8 y:11\nSaving tile x:9 y:0\nSaving tile x:9 y:1\nSaving tile x:9 y:2\nSaving tile x:9 y:3\nSaving tile x:9 y:4\nSaving tile x:9 y:5\nSaving tile x:9 y:6\nSaving tile x:9 y:7\nSaving tile x:9 y:8\nSaving tile x:9 y:9\nSaving tile x:9 y:10\nSaving tile x:9 y:11\nSaving tile x:10 y:0\nSaving tile x:10 y:1\nSaving tile x:10 y:2\nSaving tile x:10 y:3\nSaving tile x:10 y:4\nSaving tile x:10 y:5\nSaving tile x:10 y:6\nSaving tile x:10 y:7\nSaving tile x:10 y:8\nSaving tile x:10 y:9\nSaving tile x:10 y:10\nSaving tile x:10 y:11\nSaving tile x:11 y:0\nSaving tile x:11 y:1\nSaving tile x:11 y:2\nSaving tile x:11 y:3\nSaving tile x:11 y:4\nSaving tile x:11 y:5\nSaving tile x:11 y:6\nSaving tile x:11 y:7\nSaving tile x:11 y:8\nSaving tile x:11 y:9\nSaving tile x:11 y:10\nSaving tile x:11 y:11\n\n\n\nstack.shape\n\n(7, 2, 21673, 19821)"
  },
  {
    "objectID": "workflow/cell_segmentation/cellpose/run_cellpose.html",
    "href": "workflow/cell_segmentation/cellpose/run_cellpose.html",
    "title": "Run Cellpose",
    "section": "",
    "text": "It’s a lot faster with a GPU. Check with !nvidia-smi if available\n\nimport os, shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['figure.dpi'] = 150\nfrom cellpose import core, utils, io, models, metrics\nimport skimage.io\nimport tifffile\nfrom cellpose import plot\nimport random\nimport re\n\nuse_GPU = core.use_gpu()\nyn = ['NO', 'YES']\nprint(f'>>> GPU activated? {yn[use_GPU]}')\n\n>>> GPU activated? NO\n\n\n\n# call logger_setup to have output of cellpose written\nfrom cellpose.io import logger_setup\nlogger_setup();\n\n2022-06-15 08:08:14,972 [INFO] WRITING LOG OUTPUT TO /home/mheeg/.cellpose/run.log\n\n\n\nimg = skimage.io.imread(f\"scratch/full_stack.tif\")\n\n\nimg.shape\n\n(7, 2, 21673, 19821)\n\n\n\nmodel = models.CellposeModel(gpu=use_GPU, \n                             pretrained_model='models/Merscope_trained_on_10_images.model')\n\ndiameter = model.diam_labels\n\n2022-06-15 08:08:43,670 [INFO] >>>> loading model models/Merscope_trained_on_10_images.model\n2022-06-15 08:08:43,671 [INFO] >>>> using CPU\n2022-06-15 08:08:43,890 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n2022-06-15 08:08:43,890 [INFO] >>>> model diam_labels =  26.578 (mean diameter of training ROIs)\n\n\n\nmasks, flows, styles = model.eval(img, channels=[1,2], diameter=diameter, do_3D=False, stitch_threshold=0.5)\n\n2022-06-15 08:08:43,985 [INFO] multi-stack tiff read in as having 7 planes 2 channels\n2022-06-15 08:09:02,844 [INFO] 0%|          | 0/7 [00:00<?, ?it/s]\n2022-06-15 08:20:58,160 [INFO] 14%|#4        | 1/7 [11:55<1:11:31, 715.31s/it]\n2022-06-15 08:32:38,845 [INFO] 29%|##8       | 2/7 [23:35<58:53, 706.71s/it]\n2022-06-15 08:43:57,647 [INFO] 43%|####2     | 3/7 [34:54<46:15, 693.97s/it]\n2022-06-15 08:56:10,219 [INFO] 57%|#####7    | 4/7 [47:07<35:27, 709.21s/it]\n2022-06-15 09:08:36,963 [INFO] 71%|#######1  | 5/7 [59:34<24:05, 722.74s/it]\n2022-06-15 09:19:42,747 [INFO] 86%|########5 | 6/7 [1:10:39<11:43, 703.38s/it]\n\n\n\n# this command does not work since the file is too big\n# good thing is, that we only need the masks for later, so we just save that.\n# io.masks_flows_to_seg(img, masks, flows, diameter, f\"scratch/full_stack.tif\", [1,2])\n\nOverflowError: serializing a bytes object larger than 4 GiB requires pickle protocol 4 or higher\n\n\n\nnp.save(\n    file = \"cellpose_segmentation/masks.npy\",\n    arr = masks\n)"
  },
  {
    "objectID": "workflow/cell_segmentation/cellpose/index.html",
    "href": "workflow/cell_segmentation/cellpose/index.html",
    "title": "Cellpose",
    "section": "",
    "text": "See the original publications for cellpose: Stringer et al. (2021) Pachitariu and Stringer (2022)\n\n\n\n\n\n\n\n\n\n\n\n\nPrepare the images\n\n\n\n\n\nStack the different layers from the segmentation images into on big TIFF file that can be used for cellpose.\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\n\n\nTrain a model\n\n\n\n\n\nTrain a cellpose 2 model for our dataset\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\n\n\nRun Cellpose\n\n\n\n\n\nRun the trained cellpose model on the entire dataset\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\n\n\nAssing transcripts to cells\n\n\n\n\n\nUse the segmentation mask and assign the transcripts from MerFISH and auxiliary staining to cells.\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\nNo matching items\n\nReferences\n\nPachitariu, Marius, and Carsen Stringer. 2022. “Cellpose 2.0: How to Train Your Own Model.” Nature Methods 19 (12): 1634–41. https://doi.org/10.1038/s41592-022-01663-4.\n\n\nStringer, Carsen, Tim Wang, Michalis Michaelos, and Marius Pachitariu. 2021. “Cellpose: A Generalist Algorithm for Cellular Segmentation.” Nature Methods 18 (1): 100–106. https://doi.org/10.1038/s41592-020-01018-x."
  },
  {
    "objectID": "workflow/cell_segmentation/cellpose/train_model.html",
    "href": "workflow/cell_segmentation/cellpose/train_model.html",
    "title": "Train a model",
    "section": "",
    "text": "In this part, we will train a model for cell annotation. For that we will select 10 random tiles and a random z plane is that image (so a total of 10 2d images). We will use the pretrained tissuenet model and then manualy annotate these samples.\nIn a second step, we will use the annotated images to create a new and better model, that will be used for the entire dataset."
  },
  {
    "objectID": "workflow/cell_segmentation/cellpose/train_model.html#load-the-libraries",
    "href": "workflow/cell_segmentation/cellpose/train_model.html#load-the-libraries",
    "title": "Train a model",
    "section": "Load the libraries",
    "text": "Load the libraries\nAnd enable logging for cellpose\n\nimport os, shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['figure.dpi'] = 150\nfrom cellpose import core, utils, io, models, metrics\nimport skimage.io\nimport tifffile\nfrom cellpose import plot\nimport random\nimport re\n\nuse_GPU = core.use_gpu()\nyn = ['NO', 'YES']\nprint(f'>>> GPU activated? {yn[use_GPU]}')\n\n>>> GPU activated? YES\n\n\n\n# call logger_setup to have output of cellpose written\nfrom cellpose.io import logger_setup\nlogger_setup();\n\n2022-06-14 13:14:31,832 [INFO] WRITING LOG OUTPUT TO /home/mheeg/.cellpose/run.log"
  },
  {
    "objectID": "workflow/cell_segmentation/cellpose/train_model.html#select-training-images",
    "href": "workflow/cell_segmentation/cellpose/train_model.html#select-training-images",
    "title": "Train a model",
    "section": "Select training images",
    "text": "Select training images\nSelect (pseudo) random images\n\nrandom.seed(2022)\nimg_x = random.choices(range(1, 11), k=10)\nimg_y = random.choices(range(1, 11), k=10)\nimg_z = random.choices(range(0, 7), k=10)\nimg_x, img_y, img_z\n\n([6, 5, 4, 1, 8, 10, 5, 7, 9, 9],\n [8, 4, 7, 6, 6, 1, 8, 3, 10, 9],\n [2, 2, 0, 2, 3, 0, 1, 3, 0, 0])\n\n\n\n# copy the images\nfor x,y,z, i in zip(img_x, img_y, img_z, range(0,10)):\n    print(f\"image {i}: {x} {y} {z}\")\n    img = skimage.io.imread(f\"scratch/tiles/tile_{x}_{y}.tif\")[z]\n    # Add R channel with zeros. Ctyoplasm = green, nucleus = blue\n    img = np.concatenate(\n        (\n            np.zeros((1, img.shape[1], img.shape[2]),\n                    dtype=np.int8),\n            img\n        ), \n        axis = 0\n    )\n    # save\n    with tifffile.TiffWriter(f\"training/tissuenet/img_{i}.tif\") as tif:\n        tif.save(img)\n\nimage 0: 6 8 2\nimage 1: 5 4 2\nimage 2: 4 7 0\nimage 3: 1 6 2\nimage 4: 8 6 3\nimage 5: 10 1 0\nimage 6: 5 8 1\nimage 7: 7 3 3\nimage 8: 9 10 0\nimage 9: 9 9 0"
  },
  {
    "objectID": "workflow/cell_segmentation/cellpose/train_model.html#use-tissuenet-model",
    "href": "workflow/cell_segmentation/cellpose/train_model.html#use-tissuenet-model",
    "title": "Train a model",
    "section": "Use tissuenet model",
    "text": "Use tissuenet model\nwe use the tissuenet model to create a segmentaion for these files. this need to be manually checked and the new segmentation masks will be used to train a new model\n\nimport glob\nfiles = glob.glob(\"training/tissuenet/*.tif\")\nfiles.sort()    \n    \n# need to rearrange the dimension, \n# imread automatically puts RGB in dimension 2, move it back to 0\nimgs = [np.transpose(skimage.io.imread(f), [2,0,1]) for f in files]\nnimg = len(imgs)\n\nplt.figure(figsize=(16,8))\nfor k,img in enumerate(imgs):\n    plt.subplot(2,5,k+1)\n    plt.title(files[k])\n    plt.axis('off')\n    plt.imshow(plot.image_to_rgb(img[1:3,:,:], channels=[2,3]))\n\n\n\n\n\nmodel = models.CellposeModel(gpu=use_GPU, model_type='tissuenet')\n\n2022-06-14 13:14:45,399 [INFO] >> tissuenet << model set to be used\n2022-06-14 13:14:45,403 [INFO] ** TORCH CUDA version installed and working. **\n2022-06-14 13:14:45,404 [INFO] >>>> using GPU\n2022-06-14 13:14:45,925 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n\n\n\nmasks, flows, styles = model.eval(imgs, channels=[2,3], diameter=30, do_3D=False)\n\n2022-06-14 13:14:45,943 [INFO] 0%|          | 0/10 [00:00<?, ?it/s]\n2022-06-14 13:14:51,730 [INFO] 10%|#         | 1/10 [00:05<00:52,  5.79s/it]\n2022-06-14 13:14:55,227 [INFO] 20%|##        | 2/10 [00:09<00:35,  4.44s/it]\n2022-06-14 13:14:57,762 [INFO] 30%|###       | 3/10 [00:11<00:24,  3.57s/it]\n2022-06-14 13:15:01,010 [INFO] 40%|####      | 4/10 [00:15<00:20,  3.44s/it]\n2022-06-14 13:15:04,038 [INFO] 50%|#####     | 5/10 [00:18<00:16,  3.29s/it]\n2022-06-14 13:15:05,973 [INFO] 60%|######    | 6/10 [00:20<00:11,  2.83s/it]\n2022-06-14 13:15:08,824 [INFO] 70%|#######   | 7/10 [00:22<00:08,  2.84s/it]\n2022-06-14 13:15:11,914 [INFO] 80%|########  | 8/10 [00:25<00:05,  2.92s/it]\n2022-06-14 13:15:14,037 [INFO] 90%|######### | 9/10 [00:28<00:02,  2.67s/it]\n2022-06-14 13:15:16,643 [INFO] 100%|##########| 10/10 [00:30<00:00,  2.65s/it]\n2022-06-14 13:15:16,644 [INFO] 100%|##########| 10/10 [00:30<00:00,  3.07s/it]\n\n\n\nfor idx in range(len(imgs)):\n    maski = masks[idx]\n    flowi = flows[idx][0]\n    fig = plt.figure(figsize=(12,5))\n    plot.show_segmentation(fig, imgs[idx][1:3,:,:], maski, flowi, channels=[2,3])\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom cellpose import io\nio.masks_flows_to_seg(imgs, masks, flows, 30, files, [2,3])"
  },
  {
    "objectID": "workflow/cell_segmentation/cellpose/train_model.html#improve-model",
    "href": "workflow/cell_segmentation/cellpose/train_model.html#improve-model",
    "title": "Train a model",
    "section": "Improve model",
    "text": "Improve model\nwe will look for the manually annoated masks and train a new model\n\ndef improve_model(model, n_epochs=100, learning_rate=0.1, weight_decay=0.0001):\n    # get files\n    output = io.load_train_test_data(\"training/annotated\", None, mask_filter='_seg.npy')\n    train_data, train_labels, _, test_data, test_labels, _ = output\n    n_annotated = len(train_data)\n    print(f\"Found {n_annotated} images. Using these to create a new model\")\n    \n    new_model_path = model.train(train_data, train_labels, \n                                  test_data=test_data,\n                                  test_labels=test_labels,\n                                  channels=[2,3], \n                                  save_path=\".\", \n                                  n_epochs=n_epochs,\n                                  learning_rate=learning_rate, \n                                  weight_decay=weight_decay, \n                                  nimg_per_epoch=8,\n                                  model_name=f\"Merscope_trained_on_{n_annotated}_images.model\")\n    return(new_model_path)\n\n\nmodel = models.CellposeModel(gpu=use_GPU, model_type='tissuenet')\nnew_model_path = improve_model(model)\n\n2022-06-14 13:29:11,736 [INFO] >> tissuenet << model set to be used\n2022-06-14 13:29:11,743 [INFO] ** TORCH CUDA version installed and working. **\n2022-06-14 13:29:11,744 [INFO] >>>> using GPU\n2022-06-14 13:29:12,087 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n2022-06-14 13:29:12,107 [INFO] not all flows are present, running flow generation for all images\n2022-06-14 13:29:13,048 [INFO] 9 / 9 images in training/annotated folder have labels\nFound 9 images. Using these to create a new model\n2022-06-14 13:29:14,716 [INFO] computing flows for labels\n\n\n 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 5/9 [00:03<00:02,  1.44it/s]\n\n\n2022-06-14 13:29:18,418 [WARNING] empty masks!\n\n\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:05<00:00,  1.77it/s]\n\n\n2022-06-14 13:29:20,358 [WARNING] 1 train images with number of masks less than min_train_masks (5), removing from train set\n2022-06-14 13:29:20,718 [INFO] >>>> median diameter set to = 30\n2022-06-14 13:29:20,720 [INFO] >>>> mean of training label mask diameters (saved to model) 26.532\n2022-06-14 13:29:20,721 [INFO] >>>> training network with 2 channel input <<<<\n2022-06-14 13:29:20,722 [INFO] >>>> LR: 0.10000, batch_size: 8, weight_decay: 0.00010\n2022-06-14 13:29:20,723 [INFO] >>>> ntrain = 8\n2022-06-14 13:29:20,724 [INFO] >>>> nimg_per_epoch = 8\n2022-06-14 13:29:21,189 [INFO] Epoch 0, Time  0.5s, Loss 0.8753, LR 0.0000\n2022-06-14 13:29:21,596 [INFO] saving network parameters to ./models/Merscope_trained_on_9_images.model\n2022-06-14 13:29:23,530 [INFO] Epoch 5, Time  2.8s, Loss 1.0289, LR 0.0556\n2022-06-14 13:29:25,698 [INFO] Epoch 10, Time  5.0s, Loss 0.7992, LR 0.1000\n2022-06-14 13:29:29,973 [INFO] Epoch 20, Time  9.2s, Loss 0.6929, LR 0.1000\n2022-06-14 13:29:34,230 [INFO] Epoch 30, Time 13.5s, Loss 0.5619, LR 0.1000\n2022-06-14 13:29:38,500 [INFO] Epoch 40, Time 17.8s, Loss 0.5427, LR 0.1000\n2022-06-14 13:29:42,808 [INFO] Epoch 50, Time 22.1s, Loss 0.4464, LR 0.1000\n2022-06-14 13:29:47,118 [INFO] Epoch 60, Time 26.4s, Loss 0.4770, LR 0.1000\n2022-06-14 13:29:51,218 [INFO] Epoch 70, Time 30.5s, Loss 0.4274, LR 0.1000\n2022-06-14 13:29:55,522 [INFO] Epoch 80, Time 34.8s, Loss 0.3809, LR 0.1000\n2022-06-14 13:29:59,788 [INFO] Epoch 90, Time 39.1s, Loss 0.4069, LR 0.1000\n2022-06-14 13:30:03,684 [INFO] saving network parameters to ./models/Merscope_trained_on_9_images.model\n\n\n\nUse the model to annoate the next sample\n\n# declare model\nmodel = models.CellposeModel(gpu=use_GPU, \n                             pretrained_model=new_model_path)\n\ndiameter = model.diam_labels\nnext_img_no = re.search(r\"[0-9]+\", new_model_path).group(0)\nnext_img_no = int(next_img_no)\n\nnext_img = imgs[next_img_no]\n\n2022-06-14 13:30:45,682 [INFO] >>>> loading model ./models/Merscope_trained_on_9_images.model\n2022-06-14 13:30:45,695 [INFO] ** TORCH CUDA version installed and working. **\n2022-06-14 13:30:45,697 [INFO] >>>> using GPU\n2022-06-14 13:30:46,052 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n2022-06-14 13:30:46,054 [INFO] >>>> model diam_labels =  26.532 (mean diameter of training ROIs)\n\n\n\nmasks, flows, styles = model.eval(next_img, channels=[2,3], diameter=diameter, do_3D=False)\n\n\nfig = plt.figure(figsize=(12,5))\nplot.show_segmentation(fig, next_img[1:3,:,:], masks, flows[0], channels=[2,3])\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nio.masks_flows_to_seg(next_img, masks, flows, diameter, f\"training/next/img_{next_img_no}.tif\", [2,3])"
  },
  {
    "objectID": "workflow/cell_segmentation/cellpose/train_model.html#train-final-model",
    "href": "workflow/cell_segmentation/cellpose/train_model.html#train-final-model",
    "title": "Train a model",
    "section": "Train final model",
    "text": "Train final model\n\nmodel = models.CellposeModel(gpu=use_GPU, model_type='tissuenet')\nnew_model_path = improve_model(model, n_epochs=1000)\n\n2022-06-14 13:40:10,647 [INFO] >> tissuenet << model set to be used\n2022-06-14 13:40:10,655 [INFO] ** TORCH CUDA version installed and working. **\n2022-06-14 13:40:10,656 [INFO] >>>> using GPU\n2022-06-14 13:40:10,998 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n2022-06-14 13:40:11,015 [INFO] not all flows are present, running flow generation for all images\n2022-06-14 13:40:12,054 [INFO] 10 / 10 images in training/annotated folder have labels\nFound 10 images. Using these to create a new model\n2022-06-14 13:40:13,921 [INFO] computing flows for labels\n\n\n 50%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                    | 5/10 [00:03<00:03,  1.43it/s]\n\n\n2022-06-14 13:40:17,648 [WARNING] empty masks!\n\n\n100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.92it/s]\n\n\n2022-06-14 13:40:19,734 [WARNING] 1 train images with number of masks less than min_train_masks (5), removing from train set\n2022-06-14 13:40:20,136 [INFO] >>>> median diameter set to = 30\n2022-06-14 13:40:20,137 [INFO] >>>> mean of training label mask diameters (saved to model) 26.578\n2022-06-14 13:40:20,139 [INFO] >>>> training network with 2 channel input <<<<\n2022-06-14 13:40:20,140 [INFO] >>>> LR: 0.10000, batch_size: 8, weight_decay: 0.00010\n2022-06-14 13:40:20,140 [INFO] >>>> ntrain = 9\n2022-06-14 13:40:20,141 [INFO] >>>> nimg_per_epoch = 9\n2022-06-14 13:40:20,696 [INFO] Epoch 0, Time  0.6s, Loss 1.1711, LR 0.0000\n2022-06-14 13:40:21,197 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n2022-06-14 13:40:23,462 [INFO] Epoch 5, Time  3.3s, Loss 0.8996, LR 0.0556\n2022-06-14 13:40:26,065 [INFO] Epoch 10, Time  5.9s, Loss 0.7481, LR 0.1000\n2022-06-14 13:40:31,151 [INFO] Epoch 20, Time 11.0s, Loss 0.6131, LR 0.1000\n2022-06-14 13:40:36,214 [INFO] Epoch 30, Time 16.1s, Loss 0.5503, LR 0.1000\n2022-06-14 13:40:41,245 [INFO] Epoch 40, Time 21.1s, Loss 0.5119, LR 0.1000\n2022-06-14 13:40:46,411 [INFO] Epoch 50, Time 26.3s, Loss 0.4913, LR 0.1000\n2022-06-14 13:40:51,522 [INFO] Epoch 60, Time 31.4s, Loss 0.5520, LR 0.1000\n2022-06-14 13:40:56,489 [INFO] Epoch 70, Time 36.3s, Loss 0.4917, LR 0.1000\n2022-06-14 13:41:01,629 [INFO] Epoch 80, Time 41.5s, Loss 0.5035, LR 0.1000\n2022-06-14 13:41:06,724 [INFO] Epoch 90, Time 46.6s, Loss 0.4832, LR 0.1000\n2022-06-14 13:41:11,894 [INFO] Epoch 100, Time 51.8s, Loss 0.4727, LR 0.1000\n2022-06-14 13:41:12,433 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n2022-06-14 13:41:17,254 [INFO] Epoch 110, Time 57.1s, Loss 0.5320, LR 0.1000\n2022-06-14 13:41:22,263 [INFO] Epoch 120, Time 62.1s, Loss 0.4933, LR 0.1000\n2022-06-14 13:41:27,319 [INFO] Epoch 130, Time 67.2s, Loss 0.4607, LR 0.1000\n2022-06-14 13:41:32,317 [INFO] Epoch 140, Time 72.2s, Loss 0.5021, LR 0.1000\n2022-06-14 13:41:37,582 [INFO] Epoch 150, Time 77.4s, Loss 0.4970, LR 0.1000\n2022-06-14 13:41:42,935 [INFO] Epoch 160, Time 82.8s, Loss 0.5038, LR 0.1000\n2022-06-14 13:41:48,267 [INFO] Epoch 170, Time 88.1s, Loss 0.4462, LR 0.1000\n2022-06-14 13:41:53,355 [INFO] Epoch 180, Time 93.2s, Loss 0.4494, LR 0.1000\n2022-06-14 13:41:58,556 [INFO] Epoch 190, Time 98.4s, Loss 0.5173, LR 0.1000\n2022-06-14 13:42:03,669 [INFO] Epoch 200, Time 103.5s, Loss 0.4926, LR 0.1000\n2022-06-14 13:42:04,159 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n2022-06-14 13:42:09,042 [INFO] Epoch 210, Time 108.9s, Loss 0.4710, LR 0.1000\n2022-06-14 13:42:14,125 [INFO] Epoch 220, Time 114.0s, Loss 0.4431, LR 0.1000\n2022-06-14 13:42:19,161 [INFO] Epoch 230, Time 119.0s, Loss 0.5570, LR 0.1000\n2022-06-14 13:42:24,338 [INFO] Epoch 240, Time 124.2s, Loss 0.4870, LR 0.1000\n2022-06-14 13:42:29,452 [INFO] Epoch 250, Time 129.3s, Loss 0.5446, LR 0.1000\n2022-06-14 13:42:34,448 [INFO] Epoch 260, Time 134.3s, Loss 0.4514, LR 0.1000\n2022-06-14 13:42:39,660 [INFO] Epoch 270, Time 139.5s, Loss 0.5238, LR 0.1000\n2022-06-14 13:42:44,795 [INFO] Epoch 280, Time 144.7s, Loss 0.5156, LR 0.1000\n2022-06-14 13:42:49,823 [INFO] Epoch 290, Time 149.7s, Loss 0.4617, LR 0.1000\n2022-06-14 13:42:55,093 [INFO] Epoch 300, Time 155.0s, Loss 0.4354, LR 0.1000\n2022-06-14 13:42:55,581 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n2022-06-14 13:43:00,339 [INFO] Epoch 310, Time 160.2s, Loss 0.4784, LR 0.1000\n2022-06-14 13:43:05,426 [INFO] Epoch 320, Time 165.3s, Loss 0.5264, LR 0.1000\n2022-06-14 13:43:10,700 [INFO] Epoch 330, Time 170.6s, Loss 0.5179, LR 0.1000\n2022-06-14 13:43:15,714 [INFO] Epoch 340, Time 175.6s, Loss 0.4898, LR 0.1000\n2022-06-14 13:43:20,751 [INFO] Epoch 350, Time 180.6s, Loss 0.4958, LR 0.1000\n2022-06-14 13:43:25,737 [INFO] Epoch 360, Time 185.6s, Loss 0.5095, LR 0.1000\n2022-06-14 13:43:30,991 [INFO] Epoch 370, Time 190.8s, Loss 0.4858, LR 0.1000\n2022-06-14 13:43:36,208 [INFO] Epoch 380, Time 196.1s, Loss 0.4198, LR 0.1000\n2022-06-14 13:43:41,294 [INFO] Epoch 390, Time 201.2s, Loss 0.4561, LR 0.1000\n2022-06-14 13:43:46,428 [INFO] Epoch 400, Time 206.3s, Loss 0.4760, LR 0.1000\n2022-06-14 13:43:46,869 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n2022-06-14 13:43:51,721 [INFO] Epoch 410, Time 211.6s, Loss 0.4135, LR 0.1000\n2022-06-14 13:43:56,672 [INFO] Epoch 420, Time 216.5s, Loss 0.4787, LR 0.1000\n2022-06-14 13:44:01,595 [INFO] Epoch 430, Time 221.5s, Loss 0.3657, LR 0.1000\n2022-06-14 13:44:06,767 [INFO] Epoch 440, Time 226.6s, Loss 0.5036, LR 0.1000\n2022-06-14 13:44:11,994 [INFO] Epoch 450, Time 231.9s, Loss 0.4344, LR 0.1000\n2022-06-14 13:44:17,013 [INFO] Epoch 460, Time 236.9s, Loss 0.4055, LR 0.1000\n2022-06-14 13:44:22,104 [INFO] Epoch 470, Time 242.0s, Loss 0.4449, LR 0.1000\n2022-06-14 13:44:27,214 [INFO] Epoch 480, Time 247.1s, Loss 0.4728, LR 0.1000\n2022-06-14 13:44:32,342 [INFO] Epoch 490, Time 252.2s, Loss 0.4955, LR 0.1000\n2022-06-14 13:44:37,496 [INFO] Epoch 500, Time 257.4s, Loss 0.4247, LR 0.1000\n2022-06-14 13:44:37,981 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n2022-06-14 13:44:42,801 [INFO] Epoch 510, Time 262.7s, Loss 0.4491, LR 0.1000\n2022-06-14 13:44:47,840 [INFO] Epoch 520, Time 267.7s, Loss 0.4486, LR 0.1000\n2022-06-14 13:44:52,887 [INFO] Epoch 530, Time 272.7s, Loss 0.4992, LR 0.1000\n2022-06-14 13:44:58,058 [INFO] Epoch 540, Time 277.9s, Loss 0.4639, LR 0.1000\n2022-06-14 13:45:03,083 [INFO] Epoch 550, Time 282.9s, Loss 0.4873, LR 0.1000\n2022-06-14 13:45:08,382 [INFO] Epoch 560, Time 288.2s, Loss 0.4315, LR 0.1000\n2022-06-14 13:45:13,504 [INFO] Epoch 570, Time 293.4s, Loss 0.4694, LR 0.1000\n2022-06-14 13:45:18,677 [INFO] Epoch 580, Time 298.5s, Loss 0.4919, LR 0.1000\n2022-06-14 13:45:23,699 [INFO] Epoch 590, Time 303.6s, Loss 0.4458, LR 0.1000\n2022-06-14 13:45:28,861 [INFO] Epoch 600, Time 308.7s, Loss 0.3648, LR 0.1000\n2022-06-14 13:45:29,326 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n2022-06-14 13:45:34,134 [INFO] Epoch 610, Time 314.0s, Loss 0.4291, LR 0.1000\n2022-06-14 13:45:39,323 [INFO] Epoch 620, Time 319.2s, Loss 0.4198, LR 0.1000\n2022-06-14 13:45:44,152 [INFO] Epoch 630, Time 324.0s, Loss 0.3828, LR 0.1000\n2022-06-14 13:45:49,150 [INFO] Epoch 640, Time 329.0s, Loss 0.4502, LR 0.1000\n2022-06-14 13:45:54,222 [INFO] Epoch 650, Time 334.1s, Loss 0.4235, LR 0.1000\n2022-06-14 13:45:59,315 [INFO] Epoch 660, Time 339.2s, Loss 0.5020, LR 0.1000\n2022-06-14 13:46:04,380 [INFO] Epoch 670, Time 344.2s, Loss 0.4973, LR 0.1000\n2022-06-14 13:46:09,424 [INFO] Epoch 680, Time 349.3s, Loss 0.4759, LR 0.1000\n2022-06-14 13:46:14,503 [INFO] Epoch 690, Time 354.4s, Loss 0.3948, LR 0.1000\n2022-06-14 13:46:19,683 [INFO] Epoch 700, Time 359.5s, Loss 0.5076, LR 0.1000\n2022-06-14 13:46:20,203 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n2022-06-14 13:46:24,997 [INFO] Epoch 710, Time 364.9s, Loss 0.3656, LR 0.1000\n2022-06-14 13:46:30,265 [INFO] Epoch 720, Time 370.1s, Loss 0.4531, LR 0.1000\n2022-06-14 13:46:35,221 [INFO] Epoch 730, Time 375.1s, Loss 0.4754, LR 0.1000\n2022-06-14 13:46:40,461 [INFO] Epoch 740, Time 380.3s, Loss 0.4819, LR 0.1000\n2022-06-14 13:46:45,643 [INFO] Epoch 750, Time 385.5s, Loss 0.4303, LR 0.1000\n2022-06-14 13:46:50,830 [INFO] Epoch 760, Time 390.7s, Loss 0.4983, LR 0.1000\n2022-06-14 13:46:55,941 [INFO] Epoch 770, Time 395.8s, Loss 0.4621, LR 0.1000\n2022-06-14 13:47:00,998 [INFO] Epoch 780, Time 400.9s, Loss 0.4670, LR 0.1000\n2022-06-14 13:47:06,158 [INFO] Epoch 790, Time 406.0s, Loss 0.4120, LR 0.1000\n2022-06-14 13:47:11,159 [INFO] Epoch 800, Time 411.0s, Loss 0.5018, LR 0.1000\n2022-06-14 13:47:11,686 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n2022-06-14 13:47:16,497 [INFO] Epoch 810, Time 416.4s, Loss 0.4281, LR 0.1000\n2022-06-14 13:47:21,485 [INFO] Epoch 820, Time 421.3s, Loss 0.4981, LR 0.1000\n2022-06-14 13:47:26,639 [INFO] Epoch 830, Time 426.5s, Loss 0.4638, LR 0.1000\n2022-06-14 13:47:31,862 [INFO] Epoch 840, Time 431.7s, Loss 0.4312, LR 0.1000\n2022-06-14 13:47:36,876 [INFO] Epoch 850, Time 436.7s, Loss 0.4297, LR 0.1000\n2022-06-14 13:47:41,744 [INFO] Epoch 860, Time 441.6s, Loss 0.4120, LR 0.1000\n2022-06-14 13:47:46,795 [INFO] Epoch 870, Time 446.7s, Loss 0.4598, LR 0.1000\n2022-06-14 13:47:51,735 [INFO] Epoch 880, Time 451.6s, Loss 0.4376, LR 0.1000\n2022-06-14 13:47:56,934 [INFO] Epoch 890, Time 456.8s, Loss 0.4409, LR 0.1000\n2022-06-14 13:48:02,098 [INFO] Epoch 900, Time 462.0s, Loss 0.5283, LR 0.1000\n2022-06-14 13:48:02,602 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n2022-06-14 13:48:07,389 [INFO] Epoch 910, Time 467.2s, Loss 0.5465, LR 0.0500\n2022-06-14 13:48:12,701 [INFO] Epoch 920, Time 472.6s, Loss 0.6546, LR 0.0250\n2022-06-14 13:48:17,615 [INFO] Epoch 930, Time 477.5s, Loss 0.5360, LR 0.0125\n2022-06-14 13:48:22,656 [INFO] Epoch 940, Time 482.5s, Loss 0.4898, LR 0.0063\n2022-06-14 13:48:27,858 [INFO] Epoch 950, Time 487.7s, Loss 0.5352, LR 0.0031\n2022-06-14 13:48:32,688 [INFO] Epoch 960, Time 492.5s, Loss 0.4088, LR 0.0016\n2022-06-14 13:48:37,787 [INFO] Epoch 970, Time 497.6s, Loss 0.4466, LR 0.0008\n2022-06-14 13:48:42,957 [INFO] Epoch 980, Time 502.8s, Loss 0.4650, LR 0.0004\n2022-06-14 13:48:48,052 [INFO] Epoch 990, Time 507.9s, Loss 0.5434, LR 0.0002\n2022-06-14 13:48:52,465 [INFO] saving network parameters to ./models/Merscope_trained_on_10_images.model\n\n\n\nnew_model_path\n\n'./models/Merscope_trained_on_10_images.model'\n\n\n\nmodel.diam_labels\n\n26.578293809596616"
  },
  {
    "objectID": "workflow/cell_segmentation/cellpose/assing_transcripts_to_cell.html",
    "href": "workflow/cell_segmentation/cellpose/assing_transcripts_to_cell.html",
    "title": "Assing transcripts to cells",
    "section": "",
    "text": "In this notebook we will add the information from the cell segmentation to the transcripts.\nWith the MERSCOPE output we got a CSV called detected_transcripts.csv with the genes, x, y and z postitions.\nIn addition to that, we have quanitfied the auxiliary stains and merged the two transcripts files\nWe will import that file and check for each transcript, if it is in a cell, as detected by cellpose\n\n!head ../auxiliary/all_transcripts.csv | column -t -s, | cat\n\nglobal_x   global_y   global_z  gene\n3822.614   134.60324  4.0       Pycr1\n3865.5085  89.455734  5.0       Slc7a11\n3972.9065  163.4522   6.0       Cxcr3\n3968.8958  33.91168   0.0       Ldhb\n3814.5425  132.51677  0.0       Blank-42\n3664.2427  184.7953   4.0       Slc2a2\n3797.8604  28.676212  0.0       Ets1\n3687.2493  154.53114  1.0       Cxcr3\n3635.9307  184.15593  2.0       Cxcr3\n\n\nThere are a few caveats to this. We need to adjust the scace / pixel ratio. The information is stored in micron_to_mosaic_pixel_transform.csv, which is also found in the MERSCOPE output. There once again, is no good documentation about the file, but I assusme that the first two values are the scaling for x and y and the third is for z\n\n!bat ../MERLIN_output/pictures/micron_to_mosaic_pixel_transform.csv\n\n───────┬────────────────────────────────────────────────────────────────────────\n       │ File: ../MERLIN_output/pictures/micron_to_mosaic_pixel_transform.csv\n───────┼────────────────────────────────────────────────────────────────────────\n   1   │ 9.259414672851562500e+00 0.000000000000000000e+00 -0.000000000000000000\n       │ e+00\n   2   │ 0.000000000000000000e+00 9.259401321411132812e+00 -0.000000000000000000\n       │ e+00\n   3   │ 0.000000000000000000e+00 0.000000000000000000e+00 1.000000000000000000e\n       │ +00\n───────┴────────────────────────────────────────────────────────────────────────\n\n\nHowever, we need to keep in mind that we downsampled the image in order to run cellpose. We need to take that into account. We will calculte the scaling factors first.\n\n# import the libraries\nimport tifffile\nimport pandas as pd\nimport numpy as np\n\n\n# # the get the size of the original image, we can take any of the images\n# # they are all the same size\n# size_original_image = tifffile.imread(\"../Merlin_output/images/mosaic_Cellbound2_z0.tif\").shape\n# size_original_image\n\n\n# # rescaled image\n# size_rescaled_image = tifffile.imread(\"image/full_stack.tif\").shape\n# # since this is the stacked image, we dont need to keep all dimensions.\n# size_rescaled_image = size_rescaled_image[2:4]\n# size_rescaled_image\n\n\n# mmpt = pd.read_csv(\n#     \"../Merlin_output/images/micron_to_mosaic_pixel_transform.csv\", \n#     header=None, \n#     sep=' '\n# )\n# mmpt = np.array(mmpt)\n# mmpt\n\nThere is obivously no documentation about the “transformation matrix” but but inspecting the values I assume the follwoing: - The diagonal in the scaling. - the values [0,2] and [1,2] are the offset?\n\n# scale_y = size_original_image[0] / size_rescaled_image[0]\n# scale_x = size_original_image[1] / size_rescaled_image[1]\n# scale_y, scale_x\n\n# rescale = np.array([scale_x, scale_y, 1])\n# rescale\n\nNow, that we have the scaling factors, we can import the transcripts table.\n\ntranscripts = pd.read_csv(\"../auxiliary/all_transcripts.csv\")\ntranscripts\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      barcode_id\n      global_x\n      global_y\n      global_z\n      x\n      y\n      fov\n      gene\n      transcript_id\n    \n  \n  \n    \n      0\n      76052\n      29\n      4811.931152\n      133.306046\n      1.0\n      106.918274\n      1234.315186\n      0\n      Ctcf\n      ENSMUST00000005841\n    \n    \n      1\n      578964\n      170\n      4873.683594\n      128.109299\n      3.0\n      678.702148\n      1186.197266\n      0\n      Ets1\n      ENSMUST00000034534\n    \n    \n      2\n      663018\n      194\n      4963.922363\n      117.802322\n      0.0\n      1514.247681\n      1090.762207\n      0\n      Prdm1\n      ENSMUST00000039174\n    \n    \n      3\n      802336\n      241\n      4892.742188\n      192.105209\n      0.0\n      855.170471\n      1778.751831\n      0\n      Cxcr3\n      ENSMUST00000056614\n    \n    \n      4\n      805053\n      241\n      4972.506836\n      186.719177\n      3.0\n      1593.731567\n      1728.881226\n      0\n      Cxcr3\n      ENSMUST00000056614\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      260479\n      724991\n      221\n      2836.630859\n      9747.528320\n      0.0\n      337.099091\n      1358.897705\n      1467\n      Cd74\n      ENSMUST00000050487\n    \n    \n      260480\n      977945\n      298\n      2926.006836\n      9729.467773\n      0.0\n      1164.655518\n      1191.672241\n      1467\n      Arnt\n      ENSMUST00000090804\n    \n    \n      260481\n      1454933\n      435\n      2815.286865\n      9769.478516\n      0.0\n      139.470963\n      1562.134277\n      1467\n      Aldh18a1\n      ENSMUST00000176939\n    \n    \n      260482\n      1577062\n      477\n      2966.376953\n      9744.248047\n      0.0\n      1538.451660\n      1328.524292\n      1467\n      Hmgcs1\n      ENSMUST00000224188\n    \n    \n      260483\n      1706449\n      511\n      2883.143311\n      9709.230469\n      0.0\n      767.769409\n      1004.289124\n      1467\n      Blank-17\n      -1\n    \n  \n\n260484 rows × 10 columns\n\n\n\n\n# diagnoal of the matrix for scaling\n# np.diag(mmpt)\n\n\n# third col for offset,\n# but the dont want to add a value to the z axis...\n# np.append(mmpt[0:2,2], 0)\n\nLet’s test if it works with a few selected rows\n\n# from numpy.linalg import inv\n# idx = np.arange(0,20)\n# points = np.array([\n#     transcripts.global_x[idx], \n#     transcripts.global_y[idx], \n#     transcripts.global_z[idx]]\n# )\n# points = np.round(np.diag(mmpt) * points.T + np.append(mmpt[0:2,2], 0)).astype(int)\n# points\n\nIt seems to be working. So lets comment all the cells above and warp everyting into a function\n\ndef create_rescaling_function():\n    \"\"\"\n    Here we create a rescaling function that takes three argument: x, y, z.\n    These are the coordinates of out point. We will apply the transformation\n    defined in 'micron_to_mosaic_pixel_transform' to convert the micron to pixel\n    and then rescale it with the same scaling factor used in script '01'\n    \"\"\"\n    # the get the size of the original image, we can take any of the images\n    # they are all the same size\n    size_original_image = tifffile.imread(\"../Merlin_output/images/mosaic_Cellbound2_z0.tif\").shape\n    \n    # rescaled image\n    size_rescaled_image = tifffile.imread(\"image/full_stack.tif\").shape\n    # since this is the stacked image, we dont need to keep all dimensions.\n    size_rescaled_image = size_rescaled_image[2:4]\n    \n    scale_y = size_original_image[0] / size_rescaled_image[0]\n    scale_x = size_original_image[1] / size_rescaled_image[1]\n    rescale = np.array([scale_x, scale_y, 1])\n    \n    \n    mmpt = pd.read_csv(\n        \"../Merlin_output/images/micron_to_mosaic_pixel_transform.csv\", \n        header=None, \n        sep=' '\n    )\n    mmpt = np.array(mmpt)\n\n    def rescale_fun(x,y,z):\n        points = np.array([x,y,z])\n        # coordinates to pixel\n        points = np.diag(mmpt) * points.T + np.append(mmpt[0:2,2], 0)\n        # apply our scaling\n        points = points / rescale\n        return(points.T)\n    \n    return(rescale_fun)\nrescale_fun = create_rescaling_function()\nrescale_fun\n\n<function __main__.create_rescaling_function.<locals>.rescale_fun(x, y, z)>\n\n\nThere are a few Blank genes that we can remove. We do NOT want to use those for cell segmentation\n\ntranscripts = transcripts[~transcripts['gene'].str.startswith(\"Blank\")].copy()\n\n\npoints = rescale_fun(transcripts.global_x, transcripts.global_y, transcripts.global_z)\n# round to integer that we can use it with the cell segmentation mask\npoints = np.round(points).astype(int)\npoints\n\narray([[14852, 15042, 15321, ...,  8689,  9156,  8899],\n       [  411,   395,   364, ..., 30153, 30075, 29967],\n       [    1,     3,     0, ...,     0,     0,     0]])\n\n\nNext, we can import the segmentation mask from the previous script.\n\nmasks = np.load(\"cellpose_segmentation/masks.npy\")\n\nAnd we can add the cellpose_segmentation to the dataframe.\n\ntranscripts['mask'] = masks[\n  tuple(points[[2,1,0]])\n]\n\n\ntranscripts\n\n\n\n\n\n  \n    \n      \n      global_x\n      global_y\n      global_z\n      gene\n      mask\n    \n  \n  \n    \n      0\n      3822.614000\n      134.603240\n      4.0\n      Pycr1\n      0\n    \n    \n      1\n      3865.508500\n      89.455734\n      5.0\n      Slc7a11\n      0\n    \n    \n      2\n      3972.906500\n      163.452200\n      6.0\n      Cxcr3\n      0\n    \n    \n      3\n      3968.895800\n      33.911680\n      0.0\n      Ldhb\n      0\n    \n    \n      5\n      3664.242700\n      184.795300\n      4.0\n      Slc2a2\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17812303\n      3266.297176\n      6421.473477\n      6.0\n      B2m\n      0\n    \n    \n      17812304\n      3499.033270\n      6353.866514\n      6.0\n      B2m\n      136929\n    \n    \n      17812305\n      3502.489212\n      6355.486490\n      6.0\n      B2m\n      54100\n    \n    \n      17812306\n      3848.083411\n      6330.754869\n      6.0\n      B2m\n      0\n    \n    \n      17812307\n      3905.538447\n      6375.466183\n      6.0\n      B2m\n      98745\n    \n  \n\n17720905 rows × 5 columns\n\n\n\nLets see how many transcripts are in a cell.\n\nnp.sum(transcripts['mask'] > 0) / transcripts.shape[0]\n\n0.44092432073869814\n\n\nWe can now save the new transcripts.csv file and use that as an input for baysor\n\ntranscripts.to_csv(\"cellpose_segmentation/transcripts.csv\")\n\n\nnp.max(masks)\n\n137024"
  },
  {
    "objectID": "workflow/cell_segmentation/index.html",
    "href": "workflow/cell_segmentation/index.html",
    "title": "Cell segmentation",
    "section": "",
    "text": "Our two step approach includes cellpose and baysor.\n\nCellpose creates a segmentation based on the image data.\nBaysor then used the transcript neighboorhood to refine the segmentation.\n\nLastly, we put everything together in an Anndata object that can be used for downstream analysis."
  },
  {
    "objectID": "workflow/cell_segmentation/anndata/create_anndata.html",
    "href": "workflow/cell_segmentation/anndata/create_anndata.html",
    "title": "Create Anndata",
    "section": "",
    "text": "import anndata as ad\nimport scanpy as sc\nimport squidpy as sq\nimport tifffile\nimport pandas as pd\nimport swifter\nimport polars  as pl\nimport swifter\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport geopandas as gpd\nimport geojson\nimport os\nfrom scipy.spatial import ConvexHull\nfrom shapely.geometry import shape\nfrom shapely.geometry import MultiPoint\nfrom shapely.ops import transform\nimport alphashape\nfrom tqdm import tqdm\n\n\n# Set the version of baysor that we want to use\nv = 30\npath = f\"baysor_{str(v)}_mol_per_cell/\"\n\nWe start by importing the counts. As you can see, the genes are in rows and the cells in the columns. We need to transpose the table (switch rows and columns) to be compatible with anndata\n\ncounts = pd.read_csv(path + \"segmentation_counts.tsv\",sep='\\t', index_col='gene')\ncounts\n\n\n\n\n\n  \n    \n      \n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      9\n      10\n      ...\n      120685\n      120686\n      120687\n      120688\n      120689\n      120690\n      120691\n      120692\n      120693\n      120694\n    \n    \n      gene\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Abca2\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      Abcg1\n      0\n      0\n      1\n      2\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      Acly\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      Acta2\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      Adam12\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      Zfas1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      Zfp683\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      Znrf2\n      1\n      1\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      Zp3\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      mt-Nd4l\n      0\n      1\n      0\n      0\n      0\n      2\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n499 rows × 120694 columns\n\n\n\nNext, we import some more information about the cells. This includes the spatial coordinates and the size of the cell. Especially the spatial coordinates are important for some plotting functions.\n\ncells = pd.read_csv(path + \"segmentation_cell_stats.csv\", index_col=\"cell\")\ncells\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      cluster\n      n_transcripts\n      density\n      elongation\n      area\n      avg_confidence\n    \n    \n      cell\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      130.347934\n      1410.084088\n      5\n      507\n      3.197\n      1.744\n      158.600\n      1.0000\n    \n    \n      2\n      123.784174\n      1416.490865\n      2\n      416\n      4.164\n      1.319\n      99.900\n      0.9999\n    \n    \n      3\n      138.937365\n      1407.709821\n      5\n      393\n      2.659\n      1.545\n      147.800\n      0.9996\n    \n    \n      4\n      145.826591\n      1406.267540\n      2\n      172\n      2.533\n      1.929\n      67.900\n      1.0000\n    \n    \n      5\n      142.976419\n      1409.124042\n      2\n      16\n      2.022\n      4.211\n      7.914\n      1.0000\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      120690\n      2691.674300\n      669.079100\n      6\n      1\n      NaN\n      NaN\n      NaN\n      1.0000\n    \n    \n      120691\n      5225.633000\n      5751.088000\n      6\n      1\n      NaN\n      NaN\n      NaN\n      0.9999\n    \n    \n      120692\n      1583.965900\n      2634.434350\n      6\n      2\n      NaN\n      NaN\n      NaN\n      0.9998\n    \n    \n      120693\n      3159.905300\n      5049.000000\n      6\n      1\n      NaN\n      NaN\n      NaN\n      0.9775\n    \n    \n      120694\n      1896.185200\n      1018.834170\n      7\n      1\n      NaN\n      NaN\n      NaN\n      0.9999\n    \n  \n\n120694 rows × 8 columns\n\n\n\nWe also want to add the cell boundaries. We can import the GeoPandas Dataframe from step 6 again and add that to the cells table\n\n# Unfortunately the Polygons form Baysor are no good\n# See: https://github.com/kharchenkolab/Baysor/issues/15\n# gdf = gpd.read_file(path + \"segmentation_polygons_joint.shp\") \n# gdf\n\nSo instead we will create new polygons from the transcripts. Let’s import the transcripts\n\ntranscripts = pd.read_csv(path + \"segmentation.csv\")\ntranscripts\n\n\n\n\n\n  \n    \n      \n      Column1\n      x\n      y\n      z\n      gene\n      mask\n      molecule_id\n      prior_segmentation\n      confidence\n      cluster\n      cell\n      assignment_confidence\n      is_noise\n      ncv_color\n    \n  \n  \n    \n      0\n      0\n      3822.614000\n      134.603240\n      4.0\n      Pycr1\n      0\n      1\n      0\n      0.00000\n      8\n      0\n      1.00\n      True\n      #00B2FF\n    \n    \n      1\n      1\n      3865.508500\n      89.455734\n      5.0\n      Slc7a11\n      0\n      2\n      0\n      0.00000\n      4\n      0\n      1.00\n      True\n      #00B2FF\n    \n    \n      2\n      2\n      3972.906500\n      163.452200\n      6.0\n      Cxcr3\n      0\n      3\n      0\n      0.00000\n      8\n      0\n      1.00\n      True\n      #00B3FF\n    \n    \n      3\n      3\n      3968.895800\n      33.911680\n      0.0\n      Ldhb\n      0\n      4\n      0\n      0.00000\n      2\n      0\n      1.00\n      True\n      #00B2FF\n    \n    \n      4\n      5\n      3664.242700\n      184.795300\n      4.0\n      Slc2a2\n      0\n      5\n      0\n      0.00000\n      5\n      0\n      1.00\n      True\n      #9B8844\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17720900\n      17812303\n      3266.297176\n      6421.473477\n      6.0\n      B2m\n      0\n      17720901\n      0\n      1.00000\n      5\n      68623\n      1.00\n      False\n      #9C4D00\n    \n    \n      17720901\n      17812304\n      3499.033270\n      6353.866514\n      6.0\n      B2m\n      136929\n      17720902\n      136929\n      1.00000\n      5\n      69774\n      0.66\n      False\n      #A90000\n    \n    \n      17720902\n      17812305\n      3502.489212\n      6355.486490\n      6.0\n      B2m\n      54100\n      17720903\n      54100\n      1.00000\n      5\n      69873\n      1.00\n      False\n      #C90000\n    \n    \n      17720903\n      17812306\n      3848.083411\n      6330.754869\n      6.0\n      B2m\n      0\n      17720904\n      0\n      1.00000\n      5\n      111888\n      0.28\n      False\n      #974600\n    \n    \n      17720904\n      17812307\n      3905.538447\n      6375.466183\n      6.0\n      B2m\n      98745\n      17720905\n      98745\n      0.99785\n      7\n      72862\n      0.66\n      False\n      #E000F8\n    \n  \n\n17720905 rows × 14 columns\n\n\n\nPreviously I have done that by creating a convex hull. However, an alphashape might acutally be nicer. So let’s try that\n\n# # this solution here is not ideal, as the polygons can overlap\n# # but it is the best I can think of currently\n# def make_polygons(transcripts):\n#     points = transcripts[transcripts.cell != 0][['cell','x','y']]\n#     points['poly'] = gpd.points_from_xy(points.x, points.y)\n#     poly = points.groupby('cell')['poly'].agg(lambda x: MultiPoint(x.to_list()).convex_hull)\n#     poly = gpd.GeoDataFrame(poly)\n#     return(poly)\n\n# poly = make_polygons(transcripts)\n# poly\n\n\n# this is from bento\ndef _make_alphashape(points_df,x_col = 'x', y_col = 'y',alpha=0.05,buffer=0):\n    \"\"\"Generate cell boundaries from points if they are already assigned to cell numbers.\n\n    Parameters\n    ----------\n    points_df : GeoDataFrame\n        Point coordinates.\n    x_col : string\n        Column header for 'X' coordinate.\n    y_col : string\n        Column header for 'Y' coordinate.\n    alpha : float\n        Alpha parameter for generating an alpha shape around the group of points.\n    buffer: int\n        Additional padding around the points if needed. 0 by default\n    Returns\n    -------\n    cell_seg: Polygon\n        Return a shapely Polygon object as a cell segmentation mask.\n    \"\"\"\n    points = np.array([points_df[x_col],points_df[y_col]]).T\n    # create unique points\n    points = np.unique(points, axis=0)\n    cell_seg = alphashape.alphashape(points, alpha).buffer(buffer)\n    return cell_seg\n\n\npoints = transcripts[transcripts.cell != 0][['cell','x','y', 'gene']]\npoints = points.set_index('cell')\npoints\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      gene\n    \n    \n      cell\n      \n      \n      \n    \n  \n  \n    \n      12569\n      3519.302200\n      155.489910\n      Klf6\n    \n    \n      12646\n      3512.186300\n      166.390230\n      Klf6\n    \n    \n      12765\n      3536.425300\n      170.964000\n      Klf6\n    \n    \n      12765\n      3524.853300\n      171.396010\n      Klf6\n    \n    \n      12834\n      3517.636500\n      171.748400\n      Klf6\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      68623\n      3266.297176\n      6421.473477\n      B2m\n    \n    \n      69774\n      3499.033270\n      6353.866514\n      B2m\n    \n    \n      69873\n      3502.489212\n      6355.486490\n      B2m\n    \n    \n      111888\n      3848.083411\n      6330.754869\n      B2m\n    \n    \n      72862\n      3905.538447\n      6375.466183\n      B2m\n    \n  \n\n16108473 rows × 3 columns\n\n\n\n\ntqdm.pandas()\n\n\n%time poly = points.groupby('cell').progress_apply(_make_alphashape, alpha=.05)\n\n100%|█████████████████████████████████████████████████████████████████████████| 120694/120694 [44:49<00:00, 44.88it/s]\n\n\nCPU times: user 44min 42s, sys: 7.81 s, total: 44min 50s\nWall time: 44min 49s\n\n\n\n\n\n\n# fig = plt.figure(figsize=(8,5))\n# ax = fig.subplots()\n# ax.scatter(points.x, points.y)\n# gpd.GeoSeries(poly).boundary.plot(ax = ax)\n\n\npoly = gpd.GeoDataFrame({'cell_shape': poly})\npoly\n\n\n\n\n\n  \n    \n      \n      cell_shape\n    \n    \n      cell\n      \n    \n  \n  \n    \n      1\n      POLYGON ((121.90738 1410.9453, 125.958466 1414...\n    \n    \n      2\n      POLYGON ((119.71684 1412.4857, 118.00169 1416....\n    \n    \n      3\n      POLYGON ((145.00394 1410.3529, 145.53467 1406....\n    \n    \n      4\n      POLYGON ((143.04446 1401.9124, 142.22736 1402....\n    \n    \n      5\n      POLYGON ((141.25397 1406.9685, 140.95296 1407....\n    \n    \n      ...\n      ...\n    \n    \n      120690\n      POLYGON EMPTY\n    \n    \n      120691\n      POLYGON EMPTY\n    \n    \n      120692\n      POLYGON EMPTY\n    \n    \n      120693\n      POLYGON EMPTY\n    \n    \n      120694\n      POLYGON EMPTY\n    \n  \n\n120694 rows × 1 columns\n\n\n\n\ncells.shape\n\n(120694, 8)\n\n\n\n# merge cells and poly\nobs = cells.join(poly)\nobs\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      cluster\n      n_transcripts\n      density\n      elongation\n      area\n      avg_confidence\n      cell_shape\n    \n    \n      cell\n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      130.347934\n      1410.084088\n      5\n      507\n      3.197\n      1.744\n      158.600\n      1.0000\n      POLYGON ((121.90738 1410.9453, 125.958466 1414...\n    \n    \n      2\n      123.784174\n      1416.490865\n      2\n      416\n      4.164\n      1.319\n      99.900\n      0.9999\n      POLYGON ((119.71684 1412.4857, 118.00169 1416....\n    \n    \n      3\n      138.937365\n      1407.709821\n      5\n      393\n      2.659\n      1.545\n      147.800\n      0.9996\n      POLYGON ((145.00394 1410.3529, 145.53467 1406....\n    \n    \n      4\n      145.826591\n      1406.267540\n      2\n      172\n      2.533\n      1.929\n      67.900\n      1.0000\n      POLYGON ((143.04446 1401.9124, 142.22736 1402....\n    \n    \n      5\n      142.976419\n      1409.124042\n      2\n      16\n      2.022\n      4.211\n      7.914\n      1.0000\n      POLYGON ((141.25397 1406.9685, 140.95296 1407....\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      120690\n      2691.674300\n      669.079100\n      6\n      1\n      NaN\n      NaN\n      NaN\n      1.0000\n      POLYGON EMPTY\n    \n    \n      120691\n      5225.633000\n      5751.088000\n      6\n      1\n      NaN\n      NaN\n      NaN\n      0.9999\n      POLYGON EMPTY\n    \n    \n      120692\n      1583.965900\n      2634.434350\n      6\n      2\n      NaN\n      NaN\n      NaN\n      0.9998\n      POLYGON EMPTY\n    \n    \n      120693\n      3159.905300\n      5049.000000\n      6\n      1\n      NaN\n      NaN\n      NaN\n      0.9775\n      POLYGON EMPTY\n    \n    \n      120694\n      1896.185200\n      1018.834170\n      7\n      1\n      NaN\n      NaN\n      NaN\n      0.9999\n      POLYGON EMPTY\n    \n  \n\n120694 rows × 9 columns\n\n\n\nWe also want to add the transcripts to uns in anndata. We need to keep the columns gene, cell, x and y\n\nuns = {\n    'points': transcripts[['gene', 'cell', 'x', 'y']]\n}\nuns\n\n{'points':              gene    cell            x            y\n 0           Pycr1       0  3822.614000   134.603240\n 1         Slc7a11       0  3865.508500    89.455734\n 2           Cxcr3       0  3972.906500   163.452200\n 3            Ldhb       0  3968.895800    33.911680\n 4          Slc2a2       0  3664.242700   184.795300\n ...           ...     ...          ...          ...\n 17720900      B2m   68623  3266.297176  6421.473477\n 17720901      B2m   69774  3499.033270  6353.866514\n 17720902      B2m   69873  3502.489212  6355.486490\n 17720903      B2m  111888  3848.083411  6330.754869\n 17720904      B2m   72862  3905.538447  6375.466183\n \n [17720905 rows x 4 columns]}\n\n\n\nuns['points']\n\n\n\n\n\n  \n    \n      \n      gene\n      cell\n      x\n      y\n    \n  \n  \n    \n      0\n      Pycr1\n      0\n      3822.614000\n      134.603240\n    \n    \n      1\n      Slc7a11\n      0\n      3865.508500\n      89.455734\n    \n    \n      2\n      Cxcr3\n      0\n      3972.906500\n      163.452200\n    \n    \n      3\n      Ldhb\n      0\n      3968.895800\n      33.911680\n    \n    \n      4\n      Slc2a2\n      0\n      3664.242700\n      184.795300\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      17720900\n      B2m\n      68623\n      3266.297176\n      6421.473477\n    \n    \n      17720901\n      B2m\n      69774\n      3499.033270\n      6353.866514\n    \n    \n      17720902\n      B2m\n      69873\n      3502.489212\n      6355.486490\n    \n    \n      17720903\n      B2m\n      111888\n      3848.083411\n      6330.754869\n    \n    \n      17720904\n      B2m\n      72862\n      3905.538447\n      6375.466183\n    \n  \n\n17720905 rows × 4 columns\n\n\n\n\nvar = pd.DataFrame({\n    'Symbol': counts.index\n})\nvar = var.set_index('Symbol')\nvar\n\n\n\n\n\n  \n    \n      \n    \n    \n      Symbol\n    \n  \n  \n    \n      Abca2\n    \n    \n      Abcg1\n    \n    \n      Acly\n    \n    \n      Acta2\n    \n    \n      Adam12\n    \n    \n      ...\n    \n    \n      Zfas1\n    \n    \n      Zfp683\n    \n    \n      Znrf2\n    \n    \n      Zp3\n    \n    \n      mt-Nd4l\n    \n  \n\n499 rows × 0 columns\n\n\n\nLet’s create a first anndata obeject.\n\nadata = ad.AnnData(\n    X = counts.transpose().to_numpy(dtype = np.float32),\n    obs = obs,\n    obsm={\"spatial\": cells[['x', 'y']].to_numpy()},\n    uns = uns,\n    var = var\n)\nadata\n\n/projects/ps-yeolab5/t_cell_p01/home/mheeg/mambaforge/envs/cellpose/lib/python3.8/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n\n\nAnnData object with n_obs × n_vars = 120694 × 499\n    obs: 'x', 'y', 'cluster', 'n_transcripts', 'density', 'elongation', 'area', 'avg_confidence', 'cell_shape'\n    uns: 'points'\n    obsm: 'spatial'\n\n\n\nsc.pl.embedding(adata, basis=\"spatial\")\n\n\n\n\n\nsc.pl.embedding(adata, color=\"Fabp2\", basis=\"spatial\")\n\n\n\n\n\n# Convert geometry from GeoSeries to list for h5ad serialization compatibility\nadata = adata.copy()\n\nadata.obs = adata.obs.apply(\n    lambda col: col.apply(lambda val: val.wkt if val is not None else val).astype(\n        str\n    )\n    if col.astype(str).str.startswith(\"POLYGON\").any()\n    else col\n)\n\n\nadata.write(filename=path+\"anndata.h5ad\")\n\n\nadata.obs['cell_shape']\n\ncell\n1         POLYGON ((121.90738 1410.9453, 125.958466 1414...\n2         POLYGON ((119.71684 1412.4857, 118.00169 1416....\n3         POLYGON ((145.00394 1410.3529, 145.53467 1406....\n4         POLYGON ((143.04446 1401.9124, 142.22736 1402....\n5         POLYGON ((141.25397 1406.9685, 140.95296 1407....\n                                ...                        \n120690                                        POLYGON EMPTY\n120691                                        POLYGON EMPTY\n120692                                        POLYGON EMPTY\n120693                                        POLYGON EMPTY\n120694                                        POLYGON EMPTY\nName: cell_shape, Length: 120694, dtype: category\nCategories (117869, object): ['MULTIPOLYGON (((2277.3108 1000.97864, 2278.28..., 'POLYGON ((20.75769 1634.7267, 23.293108 1638...., 'POLYGON ((24.627798 1641.6558, 24.294823 1642..., 'POLYGON ((25.686134 1636.1595, 24.690582 1636..., ..., 'POLYGON ((6063.0376 4178.1567, 6062.3857 4175..., 'POLYGON ((6068.567 4227.3267, 6068.722 4225.2..., 'POLYGON ((6117.9385 4994.9014, 6118.751 4995...., 'POLYGON EMPTY']\n\n\n\nCreate plots with the new alphashape cell boundaries\n\ndef create_rescaling_function():\n    \"\"\"\n    Here we create a rescaling function that takes three argument: x, y, z.\n    These are the coordinates of out point. We will apply the transformation\n    defined in 'micron_to_mosaic_pixel_transform' to convert the micron to pixel\n    and then rescale it with the same scaling factor used in script '01'\n    \"\"\"\n    # the get the size of the original image, we can take any of the images\n    # they are all the same size\n    size_original_image = tifffile.imread(\"../Merlin_output/images/mosaic_Cellbound2_z0.tif\").shape\n    \n    # rescaled image\n    size_rescaled_image = tifffile.imread(\"image/full_stack.tif\").shape\n    # since this is the stacked image, we dont need to keep all dimensions.\n    size_rescaled_image = size_rescaled_image[2:4]\n    \n    scale_y = size_original_image[0] / size_rescaled_image[0]\n    scale_x = size_original_image[1] / size_rescaled_image[1]\n    rescale = np.array([scale_x, scale_y, 1])\n    \n    \n    mmpt = pd.read_csv(\n        \"../Merlin_output/images/micron_to_mosaic_pixel_transform.csv\", \n        header=None, \n        sep=' '\n    )\n    mmpt = np.array(mmpt)\n\n    def rescale_fun(x,y,z):\n        points = np.array([x,y,z])\n        # coordinates to pixel\n        points = np.diag(mmpt) * points.T + np.append(mmpt[0:2,2], 0)\n        # apply our scaling\n        points = points / rescale\n        return(points.T)\n    \n    return(rescale_fun)\n\n\nrescale_fun = create_rescaling_function()\nrescale_fun\n\nShaped series: series shape does not match page shape\n\n\n(3.0865665011414225, 3.0865709219772635)\n\n\n\nimg = tifffile.imread(\"cellpose_segmentation/full_stack.tif\")[3]\n\n\ndef make_image(img):\n    \"\"\" Function to format the np array for plotting\n    \n    Takes a np array of dimensions (2 x Y x X) and\n    formats it to Y x X x 3.\n    Third color is filled with zeros.\n    \n    \"\"\"\n    \n    # move the RGB to the third dimension\n    img = np.transpose(img, [1,2,0])\n    zeros = np.zeros(\n                [img.shape[0], img.shape[1], 1],\n                dtype = np.uint8\n            )\n    \n    # fill R(ed) with zeros\n    img = np.concatenate(\n        [zeros,img],\n        axis = 2\n    )\n    \n    # scale the colors from 0 to 255 to make it more intense\n    img[:,:,1] = np.uint8(img[:,:,1] / np.max(img[:,:,1]) * 255)\n    img[:,:,2] = np.uint8(img[:,:,2] / np.max(img[:,:,2]) * 255)\n    \n    \n    return(img)\n\n\n# remove empty polygons, these cause an error for plotting\npoly_draw = gpd.GeoSeries(poly.cell_shape)\npoly_draw = poly_draw[~poly_draw.is_empty]\npoly_draw\n\ncell\n1         POLYGON ((121.907 1410.945, 125.958 1414.014, ...\n2         POLYGON ((119.717 1412.486, 118.002 1416.133, ...\n3         POLYGON ((145.004 1410.353, 145.535 1406.199, ...\n4         POLYGON ((143.044 1401.912, 142.227 1402.037, ...\n5         POLYGON ((141.254 1406.968, 140.953 1407.200, ...\n                                ...                        \n120655    POLYGON ((209.430 2536.272, 208.787 2535.732, ...\n120667    POLYGON ((1675.971 3072.208, 1674.777 3072.812...\n120670    POLYGON ((2604.101 3175.266, 2603.863 3175.968...\n120681    POLYGON ((5311.925 4714.247, 5309.319 4715.523...\n120687    POLYGON ((3972.193 4236.158, 3972.064 4236.481...\nName: cell_shape, Length: 117868, dtype: geometry\n\n\nIn order to plot the polygon, we need to transform the position to the image pixed for the polygons too. The polygons only have x and y (2d). But we can easlily create the 2d wrapper function around rescale_fun. This then can be applied to the Geopandas polygon (see the example below)\n\ndef rescale_fun_2d(x,y):\n    ones = np.ones(len(x))\n    res = rescale_fun(x,y,ones)\n    return(res[0],res[1])\n    \n\n\ntransform(rescale_fun_2d, boundaries.geometry[0])\n\n\n\n\n\nfig = plt.figure(figsize = (250,250))\nax = fig.add_subplot(111)\nprint(\">>> plotting image\")\nax.imshow(\n    make_image(img),\n    interpolation = \"nearest\",\n    origin='lower'\n)\nprint(\">>> plotting transcripts\")\nax.scatter(transcripts.x*scales[0], transcripts.y*scales[1], s=0.05, c=transcripts.ncv_color)\nprint(\">>> plotting cell boundaries\")\npoly_draw.geometry.apply(lambda x: transform(rescale_fun_2d, x)).boundary.plot(ax = ax, linewidth=0.5, edgecolor=\"red\")\nax.axis('off')\nfig.tight_layout()\nprint(\">>> saving jpg\")\nfig.savefig(path+'/alphashape.jpg', dpi = 100)"
  },
  {
    "objectID": "workflow/cell_segmentation/anndata/unroll.html",
    "href": "workflow/cell_segmentation/anndata/unroll.html",
    "title": "Bonus: Unrolling",
    "section": "",
    "text": "This notebook is a first try to unroll the swiss role in the merscope experiment\n\nimport scanpy as sc\nimport anndata as ad\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as snsCreate_ImageContainer\nimport math\nfrom tqdm.notebook import tqdm \n\nsc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.figdir = \"./figures/distance_to_epithelial_cells/\"\nsc.set_figure_params(dpi=80, dpi_save=300, frameon=True, vector_friendly=True, figsize=[8,5])\n\n\n# Set the version of baysor that we want to use\nv = 30\npath = f\"baysor_{str(v)}_mol_per_cell/\"\n\n\nadata = ad.read_h5ad(path+\"anndata.h5ad\")\n\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 8))\nax = sc.pl.embedding(adata, basis=\"spatial\", ax=ax, show=False)\n\nplt.show()\n\n\n\n\n\n# To get the coordinates I used an interactive plot version.\n# %matplotlib widget\n# from mpl_point_clicker import clicker\n# fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n# ax.scatter(\n#     adata.obsm['spatial'][:,0],\n#     adata.obsm['spatial'][:,1],\n#     color='black',\n#     s=.1\n# )\n# klicker = clicker(ax, [\"event\"], markers=[\"x\"])\n# plt.show()\n# # once done, get the positions with:\n# klicker.get_positions()\n\n\n# klicker.get_positions()\n\n\nfrom scipy.interpolate import interp1d\n\n# Function to get points, these are then used to calculate a spline\n# used interactive plot to get the points\ndef getPoints():\n    points = np.array(\n       [[3877.01489361,  912.99449033],\n        [3698.65977311,  816.00683744],\n        [3536.12761867,  851.33416108],\n        [3355.53633596,  733.57641561],\n        [3174.94505325,  721.80064107],\n        [2855.90045379,  839.55838653],\n        [2633.17120511,  980.8676811 ],\n        [2434.52079413,  957.316132  ],\n        [2205.77183603, 1186.94373567],\n        [1820.51043291, 1546.10485935],\n        [1555.64321826, 1787.50823756],\n        [1212.51978111, 1922.92964485],\n        [ 869.39634396, 1911.1538703 ],\n        [ 598.50941989, 1834.61133575],\n        [ 532.29261623, 1946.48119394],\n        [ 604.52912931, 2270.31499398],\n        [ 718.90360837, 2535.26992129],\n        [1013.86937013, 2923.87048133],\n        [ 971.73140416, 3336.02259047],\n        [ 827.25837799, 3683.40793961],\n        [1037.94820782, 4254.53300513],\n        [1411.17019209, 4866.87328157],\n        [1760.31333867, 5337.90426344],\n        [2115.47619467, 5632.29862712],\n        [2675.30917108, 5914.91721624],\n        [3259.22098518, 6026.78707444],\n        [3758.85686735, 5926.69299079],\n        [4144.11827047, 5767.72003441],\n        [4529.37967359, 5508.65299437],\n        [4860.46369189, 5231.92229252],\n        [5161.44916308, 4819.77018338],\n        [5384.17841175, 4319.29976514],\n        [5444.37550599, 3842.38089599],\n        [5323.98131752, 3041.6282268 ],\n        [5131.35061596, 2576.4851322 ],\n        [4746.08921284, 2199.6603467 ],\n        [4324.70955318, 1917.04175757],\n        [4029.74379142, 1746.29302664],\n        [3457.87139616, 1493.11387389],\n        [3018.43260823, 1493.11387389],\n        [2440.54050355, 1775.73246301],\n        [1862.64839887, 2311.5302049 ],\n        [1603.80089365, 2864.9916086 ],\n        [1537.58408999, 3318.35892865],\n        [1633.89944077, 3877.70821963],\n        [1766.33304809, 4425.28173606],\n        [2133.53532294, 4872.76116884],\n        [2711.42742762, 5120.05243433],\n        [2904.05812918, 5196.59496888],\n        [3524.08819982, 5267.24961616],\n        [4168.19710816, 5108.27665978],\n        [4619.67531494, 4731.45187428],\n        [4872.50311074, 4160.32680876],\n        [4926.68049555, 3512.65920868],\n        [4752.10892226, 3006.30090316],\n        [4505.30083589, 2564.70935765],\n        [4180.23652701, 2205.54823397],\n        [3752.83715792, 2076.01471396],\n        [3325.43778884, 2081.90260123],\n        [2771.62452186, 2117.22992487],\n        [2350.2448622 , 2340.96964126],\n        [2019.16084389, 2735.45808858],\n        [1880.70752714, 3206.48907046],\n        [1910.80607426, 3830.60512144],\n        [2121.49590409, 4372.2907506 ],\n        [2548.89527318, 4784.44285974],\n        [2964.25522342, 4908.08849248],\n        [3506.02907155, 4972.85525249],\n        [3837.11308986, 4860.9853943 ],\n        [4276.55187779, 4601.91835426],\n        [4511.32054531, 4336.96342696],\n        [4571.51763955, 4189.76624512],\n        [4661.81328091, 3960.13864146],\n        [4667.83299033, 3748.17469961],\n        [4577.53734898, 3300.69526683],\n        [4390.92635684, 2917.98259406],\n        [4210.33507413, 2711.90653949],\n        [3951.48756891, 2541.15780856],\n        [3548.16703752, 2435.17583764],\n        [3120.76766843, 2423.40006309],\n        [2705.4077182 , 2505.83048492],\n        [2482.67846952, 2611.81245584],\n        [2265.96893026, 3029.85245226],\n        [2193.73241718, 3547.98653232],\n        [2271.98863969, 4060.23272511],\n        [2536.85585433, 4325.18765241],\n        [2922.11725745, 4525.37581971],\n        [3391.6545925 , 4654.90933972],\n        [3843.13279928, 4513.60004516],\n        [4174.21681759, 4213.31779422],\n        [4162.17739874, 3930.69920509],\n        [4120.03943277, 3542.09864504],\n        [4065.86204796, 3265.36794319],\n        [3981.58611603, 3182.93752136],\n        [3698.65977311, 3059.29188862],\n        [3373.59546423, 2976.86146679],\n        [3048.53115535, 3000.41301589],\n        [2855.90045379, 3141.72231045],\n        [2795.70335955, 3642.19272869],\n        [2910.0778386 , 3918.92343054],\n        [3337.47720769, 3989.57807783],\n        [3602.34442233, 4019.01751419],\n        [3740.79773908, 3924.81131782],\n        [3632.44296945, 3701.07160143],\n        [3481.95023386, 3506.7713214 ],\n        [3331.45749826, 3471.44399776],\n        [3217.08301921, 3600.97751778],\n        [3270.4645621 , 3602.28753654],\n        [3298.13278465, 3538.92419276],\n        [3357.42183298, 3528.91945427]]\n\n    )\n    return points\n\n# adapted from https://stackoverflow.com/questions/52014197/how-to-interpolate-a-2d-curve-in-python\n# interploates a spline from the individual points.\n# n = number of points to return\n# method = one of ['slinear', 'quadratic', 'cubic']\ndef getSpline(n=250, method='cubic'):\n    points = getPoints()\n    distance = np.cumsum( np.sqrt(np.sum( np.diff(points, axis=0)**2, axis=1 )) )\n    distance = np.insert(distance, 0, 0)/distance[-1]\n    alpha = np.linspace(0, 1, n)\n    interpolator =  interp1d(distance, points, kind=method, axis=0)\n    interpolated_points = interpolator(alpha)\n    return interpolated_points\n\n    \n\n\n\ndef getCenter(adata):\n    x = np.min(adata.obsm['spatial'][:,0]) + (np.max(adata.obsm['spatial'][:,0]) - np.min(adata.obsm['spatial'][:,0]))/2\n    y = np.min(adata.obsm['spatial'][:,1]) + (np.max(adata.obsm['spatial'][:,1]) - np.min(adata.obsm['spatial'][:,1]))/2\n    return np.array([x,y])\n\n\ndef orderSpline(spline, center):\n    \"\"\"\n    Order the spline so that it goes from the inside to the outside\n    \"\"\"\n    dist_start = np.linalg.norm(spline[0]-center)\n    dist_end = np.linalg.norm(spline[-1]-center)\n\n    if dist_start < dist_end:\n        return spline\n    else:\n        return np.flip(spline, axis=0)\n\n\nspline = getSpline(n=20000)\nspline = orderSpline(spline, getCenter(adata))\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 8))\nax = sc.pl.embedding(adata, basis=\"spatial\", ax=ax, show=False)\nax.plot(*spline.T, color='red')\n\n\nplt.show()\n\n\n\n\n\ndists_from_end = np.linalg.norm(spline-spline[0], axis=1)\n\n\ndef unRoll(point, spline, dists_from_end):\n    \"\"\"\n    calculates new x and y positions for a point\n\n    three steps:\n        1) remove all spline-points that where the angle between the spline-point to center and point to center is bigger than X\n        2) distance from point to center has to be bigger than distance from spline to center\n        3) get the minimun distance from point to spline after filtering (above criteria)\n    \n    \"\"\"\n    \n    # Get the angles between\n    # - point to center\n    # - all spline edges to center\n    # create mask with angles smaller than 10 degrees\n    def unit_vector(vector):\n        \"\"\" Returns the unit vector of the vector.  \"\"\"\n        return vector / np.linalg.norm(vector)\n\n    def angle_between(point, spline):\n        \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'\n        \"\"\"\n        v1_u = unit_vector(point)\n        v2_u = (spline.T / np.linalg.norm(spline, axis=1)).T\n        return np.arccos(np.clip(np.dot([v1_u], v2_u.T)[0], -1.0, 1.0))\n    \n    angles = angle_between(\n        point-spline[0],\n        spline-spline[0]\n    )\n    angles = np.array(angles)\n    # the first value is always nan (spline[0]-spline[0]), to keep that value, we set it to zero\n    angles[0] = 0\n\n    keep_angle = angles < 10/180 * math.pi\n\n    # compare distance of point to center to all spline edges to center\n    # create mask where point to center is bigger\n    dist_point = np.linalg.norm(point-spline[0])\n    keep_dist = dists_from_end<dist_point\n\n    # combine both masks\n    keep = keep_angle & keep_dist\n\n    # create the distanse from point to filteres spline edges\n    dists = np.linalg.norm(spline[keep]-point, axis=1)\n\n    # get id of the minimum\n    idx = np.arange(len(spline))[keep][np.argmin(dists)]\n    idy = dists[np.argmin(dists)]\n\n    return [idx, idy]\n\n\nnew_coords = [unRoll(point, spline, dists_from_end) for point in tqdm(adata.obsm['spatial'])]\nnew_coords = np.array(new_coords)\n\n\n\n\n/scratch/mheeg/30430932.tscc-mgr7.local/ipykernel_59318/4128264411.py:27: RuntimeWarning: invalid value encountered in true_divide\n  v2_u = (spline.T / np.linalg.norm(spline, axis=1)).T\n\n\n\n# point = adata.obsm['spatial'][1000]\n\n# x, y, keep = unRoll(point, spline, dists_from_end)\n\n# print(f\"x {x}, y {y}\")\n\n# fig, ax1 = plt.subplots(1, 1, figsize=(6, 6))\n\n# ax1.scatter(\n#     adata.obsm['spatial'][:,0],\n#     adata.obsm['spatial'][:,1],\n#     color='grey',\n#     s=.1\n# )\n# ax1.scatter(*spline[keep].T, color='red', s=.5)\n# ax1.scatter(spline[x][0], spline[x][1], color='green')\n\n# ax1.scatter(point[0], point[1], color='blue')\n# ax1.set_aspect(1)\n\n\n# plt.show()\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 6), gridspec_kw={'width_ratios': [1, 3]})\n\nax1.scatter(\n    adata.obsm['spatial'][:,0],\n    adata.obsm['spatial'][:,1],\n    c = new_coords[:,0],\n    s=.1\n)\nax1.plot(*spline.T, color='red')\nax1.scatter(spline[0][0], spline[0][1], color='green')\nax1.set_aspect(1)\n\nax2.scatter(\n    new_coords[:,0],\n    new_coords[:,1],\n    c = new_coords[:,0],\n    s=.1\n)\n\nplt.show()\n\n\n\n\nLet’s add the unrolled coordinated as a to obms.\n\nadata.obsm['unrolled'] = new_coords\n\nNow, we can use the integrated plotting functions in scanpy to use all representations. Of course we have not normalized the data yet, and we also dont have a UMAP.representations\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\nax1 = sc.pl.embedding(adata, basis='spatial', ax=ax1, color='Lyz1', show=False)\nax2 = sc.pl.embedding(adata, basis='unrolled', ax=ax2, color='Lyz1', show=False)\n\n\n\n\n\n# Yay, let's save the results\nadata.write(filename=path+\"anndata_with_unrolled.h5ad\")\n\n\n# No need to run this anymore. This is part of an old analysis\n\n\n# Make plots for P14 cells only\nidx = np.where(adata.obs['cell type'] == 'P14 T cell')[0]\n\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\n\nax.scatter(\n    adata.layers['sqrt_norm'][idx, np.where(adata.var_names == 'Tcf7')[0]],\n    new_coords[idx,1],\n    c = adata.layers['sqrt_norm'][idx, np.where(adata.var_names == 'Tcf7')[0]],\n    s=1\n)\n\nplt.show()\n\n\n\n\n\nimport seaborn as sns\n\n\nsns.kdeplot(\n    adata.layers['sqrt_norm'][idx, np.where(adata.var_names == 'Itgae')[0]],\n    new_coords[idx,1],\n    label=\"Itgae+\")\nsns.kdeplot(\n    adata.layers['sqrt_norm'][idx, np.where(adata.var_names == 'Tcf7')[0]],\n    new_coords[idx,1],\n    label=\"Tcf7+\")\nplt.legend()\n\n/home/max/mambaforge/envs/scanpy/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  warnings.warn(\n/home/max/mambaforge/envs/scanpy/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  warnings.warn(\n\n\n<matplotlib.legend.Legend at 0x7fe7c45392b0>\n\n\n\n\n\n\ndist_all_cells = new_coords[:,1]\n\ndist_all_p14 = new_coords[idx,1]\n\ndist_cd103 = new_coords[idx,1]\ndist_cd103 = dist_cd103[adata.layers['sqrt_norm'][idx, np.where(adata.var_names == 'Itgae')[0]] > 0]\ndist_cd103.shape\n\ndist_tcf7 = new_coords[idx,1]\ndist_tcf7 = dist_tcf7[adata.layers['sqrt_norm'][idx, np.where(adata.var_names == 'Tcf7')[0]] > 0]\ndist_tcf7.shape\n\ndist_il18rap = new_coords[idx,1]\ndist_il18rap = dist_il18rap[adata.layers['sqrt_norm'][idx, np.where(adata.var_names == 'Il18rap')[0]] > 0]\n\ndist_il18r1 = new_coords[idx,1]\ndist_il18r1 = dist_il18r1[adata.layers['sqrt_norm'][idx, np.where(adata.var_names == 'Il18r1')[0]] > 0]\n\n\nplt.figure(figsize = (4,8))\nsns.kdeplot(y=dist_all_cells, label=\"All cells\")\nsns.kdeplot(y=dist_all_p14, label=\"All P14\")\nsns.kdeplot(y=dist_cd103, label=\"Itgae+ P14\")\nax = sns.kdeplot(y=dist_tcf7, label=\"Tcf7+ P14\")\nax.invert_xaxis()\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fe7c2f5d3a0>\n\n\n\n\n\n\nimport scipy.stats\n\nfig = plt.figure(figsize = (8,4))\nax = fig.add_subplot(111)\n\n\nkde_all_cells = scipy.stats.gaussian_kde(dist_all_cells)\nkde_all_p14 = scipy.stats.gaussian_kde(dist_all_p14)\nkde_all_p14_cd103 = scipy.stats.gaussian_kde(dist_cd103)\nkde_all_p14_tcf7 = scipy.stats.gaussian_kde(dist_tcf7)\nkde_all_p14_il18rap = scipy.stats.gaussian_kde(dist_il18rap)\nkde_all_p14_il18r1 = scipy.stats.gaussian_kde(dist_il18r1)\n\ngrid = np.linspace(-100,1200, 1301)\n\nax.plot(grid, kde_all_p14(grid)-kde_all_cells(grid), label=\"P14 - all cells\")\nax.plot(grid, kde_all_p14_cd103(grid)-kde_all_cells(grid), label=\"Itgae+ P14 - all cells\")\nax.plot(grid, kde_all_p14_tcf7(grid)-kde_all_cells(grid), label=\"Tcf7+ P14 - all cells\")\n\nax.set_ylabel(\"Difference in density\")\nax.set_xlabel(\"Distance to basal membrane\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\nimport scipy.stats\n\nfig = plt.figure(figsize = (8,4))\nax = fig.add_subplot(111)\n\n\ngrid = np.linspace(-100,1200, 1301)\n\nax.plot(grid, kde_all_p14_cd103(grid)-kde_all_p14(grid), label=\"Itgae+ P14\")\nax.plot(grid, kde_all_p14_tcf7(grid)-kde_all_p14(grid), label=\"Tcf7+ P14\")\n\nax.set_ylabel(\"Difference in density\\ncompared to all P14 cells\")\nax.set_xlabel(\"Distance to basal membrane\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\nimport scipy.stats\n\nfig = plt.figure(figsize = (8,4))\nax = fig.add_subplot(111)\n\n\ngrid = np.linspace(-100,1200, 1301)\n\nax.plot(grid, kde_all_p14_cd103(grid), label=\"Itgae+\")\nax.plot(grid, kde_all_p14_tcf7(grid), label=\"Tcf7+\")\nax.plot(grid, kde_all_p14_cd103(grid)-kde_all_p14_tcf7(grid), label=\"Difference\")\n\nax.set_ylabel(\"gaussian_kde\")\nax.set_xlabel(\"Distance to basal membrane\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\nimport scipy.stats\n\nfig = plt.figure(figsize = (8,4))\nax = fig.add_subplot(111)\n\n\ngrid = np.linspace(-100,1200, 1301)\n\nax.plot(grid, kde_all_p14_cd103(grid), label=\"Itgae+\")\nax.plot(grid, kde_all_p14_il18rap(grid), label=\"Il18rap+\")\nax.plot(grid, kde_all_p14_cd103(grid)-kde_all_p14_il18rap(grid), label=\"Difference\")\n\nax.set_ylabel(\"gaussian_kde\")\nax.set_xlabel(\"Distance to basal membrane\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\nfig = plt.figure(figsize = (8,4))\nax = fig.add_subplot(111)\n\n\ngrid = np.linspace(-100,1200, 1301)\n\nax.plot(grid, kde_all_p14_cd103(grid), label=\"Itgae+\")\nax.plot(grid, kde_all_p14_il18r1(grid), label=\"Il18r1+\")\nax.plot(grid, kde_all_p14_cd103(grid)-kde_all_p14_il18r1(grid), label=\"Difference\")\n\nax.set_ylabel(\"gaussian_kde\")\nax.set_xlabel(\"Distance to basal membrane\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n# test all genes for expression along the y axis\n\n\nrho, p = scipy.stats.spearmanr(new_coords[idx,1], adata.layers['sqrt_norm'][idx])\n# the return value is a matrix, we subset the first row and remove the first value\nrho = rho[0, 1:]\np = p[0, 1:]\n# lets find the ones that are significant\nsig_genes = np.where(p <= 0.05)[0]\n\n\ncorrelating_genes = pd.DataFrame({\n    'gene': adata.var_names[sig_genes],\n    'rho': rho[sig_genes],\n    'p': p[sig_genes]\n})\n\n\ncorrelating_genes.to_csv('gene_correlation_to_distance_to_membrane.csv')"
  },
  {
    "objectID": "workflow/cell_segmentation/anndata/compare_baysor_runs.html",
    "href": "workflow/cell_segmentation/anndata/compare_baysor_runs.html",
    "title": "Compare the different segmentation runs",
    "section": "",
    "text": "In our first experiment, we tested many mol_per_cell settings. In the later runs, we just took 30 since this seems to be a good value.\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as pltgeopandas.GeoSeries(\n\n\nversions = [30]\n\n\ndef diagnostic_plots(transcripts, title, ax1, ax2, ax3):\n    \n    # how many transcripts are assigned to a cell\n    transcript_in_cell = (transcripts.cell > 0).value_counts()\n    ax1.pie(transcript_in_cell, explode=[0.1, 0], labels=['in cell', 'not in cell'], \n           autopct='%1.1f%%',\n            startangle=90)\n    ax1.axis('equal') # to make a circle\n    ax1.set_title(f\"Transcripts assigned to cell \\n total: {np.max(transcripts.cell)} cells\")\n\n    # how many transcripts per cell\n    transcripts_per_cell = transcripts[transcripts.cell > 0].groupby(\"cell\").size()\n    ax2.hist(np.log10(transcripts_per_cell), bins=50, rwidth=0.9,color='#607c8e')\n    add_mean_and_median(transcripts_per_cell, ax2, fn = lambda x:np.log10(x))\n    ax2.set_xlabel(r\"$log_{10}(Transcripts\\ per\\ cell)$\")\n    ax2.set_ylabel(r\"$cells$\")\n    ax2.set_title(f\"Transcripts per cell\\nm = {title}\")\n    # np.log10(transcripts[transcripts.cell > 0].groupby(\"cell\").size()).plot.hist(grid=True, bins=50, rwidth=0.9,color='#607c8e')\n\n\n    # how many features per cell\n    features_per_cell = transcripts[transcripts.cell > 0].groupby(\"cell\")['gene'].nunique()\n    ax3.hist(features_per_cell, bins=50, rwidth=0.9,color='#607c8e')\n    add_mean_and_median(features_per_cell, ax3)\n    ax3.set_xlabel(r\"$Features\\ per\\ cell$\")\n    ax3.set_ylabel(r\"$cells$\")\n    ax3.set_title(\"Features per cell\")\n\n    return(ax1, ax2, ax3)\n\ndef add_mean_and_median(values, ax, fn = lambda x:x):\n    mean = values.mean()\n    median = values.median()\n    ax.axvline(fn(mean), color='k', linestyle='dashed', linewidth=1)\n    ax.axvline(fn(median), color='m', linestyle='dashed', linewidth=1)\n    min_ylim, max_ylim = ax.get_ylim()\n    xpos = max(fn(mean)*1.1, fn(median)*1.1)\n    ax.text(xpos, max_ylim*0.9, 'Mean: {:.2f}\\nMedian: {:.2f}'.format(mean, median))\n\n\nnrows = len(versions)\n\nfig = plt.figure(figsize = (14,4*nrows))\n\nfor i in range(nrows):\n    v = versions[i]\n    print(f\">>> making plots for m = {v}\")\n    ax1 = fig.add_subplot(nrows,3,1+i*3)\n    ax2 = fig.add_subplot(nrows,3,2+i*3)\n    ax3 = fig.add_subplot(nrows,3,3+i*3)\n\n    transcripts = pd.read_csv(\"baysor_\"+str(v)+\"_mol_per_cell/segmentation.csv\")\n\n    ax1, ax3, ax3 = diagnostic_plots(transcripts, v, ax1, ax2, ax3)\n\nfig.tight_layout(h_pad=1.1)\nfig.savefig('07_diagnostic_plots.jpg', dpi = 100)\n\n\n>>> making plots for m = 30"
  },
  {
    "objectID": "workflow/cell_segmentation/anndata/index.html",
    "href": "workflow/cell_segmentation/anndata/index.html",
    "title": "Anndata",
    "section": "",
    "text": "As a bonus, we do the unrolling on the jelly role here too.\n\n\n\n\n\n\n\n\n\n\nPlots for cell segmentation\n\n\n\n\n\nTo see if the segmentation is acutally working we will generate a few plots for visualization. We will combine the TIF files and the cell polygons and the individual transcripts.\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\n\n\nCompare the different segmentation runs\n\n\n\n\n\nIf you tried Baysor with various settings, you can compare the runs here.\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\n\n\nCreate Anndata\n\n\n\n\n\nPut everything together in an Anndata object that can be used with pyhton or R for further analysis\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\n\n\nBonus: Unrolling\n\n\n\n\n\nAs a bonus, we unroll the jelly role here, too, to facilitate downstream analysis.\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workflow/cell_segmentation/anndata/segmentation_plots.html",
    "href": "workflow/cell_segmentation/anndata/segmentation_plots.html",
    "title": "Plots for cell segmentation",
    "section": "",
    "text": "# import the libraries\nimport tifffile\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport geopandas as gpd\nimport geojson\nimport os\nfrom shapely.geometry import shape\nfrom shapely.ops import transform"
  },
  {
    "objectID": "workflow/cell_segmentation/anndata/segmentation_plots.html#define-path",
    "href": "workflow/cell_segmentation/anndata/segmentation_plots.html#define-path",
    "title": "Plots for cell segmentation",
    "section": "Define Path",
    "text": "Define Path\nI am running Baysor with different parameters, to see which one is the best fit, we will define a path here so that we can use the same script for all runs\n\npath = \"baysor_3_mol_per_cell/\"\n\nSimilar to the 04_add_cell_to_transcripts notebook, we will need to get the scaling factors to combine the TIF and the merscope coordinates.\n\ndef create_rescaling_function():\n    \"\"\"\n    Here we create a rescaling function that takes three argument: x, y, z.\n    These are the coordinates of out point. We will apply the transformation\n    defined in 'micron_to_mosaic_pixel_transform' to convert the micron to pixel\n    and then rescale it with the same scaling factor used in script '01'\n    \"\"\"\n    # the get the size of the original image, we can take any of the images\n    # they are all the same size\n    size_original_image = tifffile.imread(\"../Merlin_output/images/mosaic_Cellbound2_z0.tif\").shape\n    \n    # rescaled image\n    size_rescaled_image = tifffile.imread(\"image/full_stack.tif\").shape\n    # since this is the stacked image, we dont need to keep all dimensions.\n    size_rescaled_image = size_rescaled_image[2:4]\n    \n    scale_y = size_original_image[0] / size_rescaled_image[0]\n    scale_x = size_original_image[1] / size_rescaled_image[1]\n    rescale = np.array([scale_x, scale_y, 1])\n    \n    \n    mmpt = pd.read_csv(\n        \"../Merlin_output/images/micron_to_mosaic_pixel_transform.csv\", \n        header=None, \n        sep=' '\n    )\n    mmpt = np.array(mmpt)\n\n    def rescale_fun(x,y,z):\n        points = np.array([x,y,z])\n        # coordinates to pixel\n        points = np.diag(mmpt) * points.T + np.append(mmpt[0:2,2], 0)\n        # apply our scaling\n        points = points / rescale\n        return(points.T)\n    \n    return(rescale_fun)\n\n\nrescale_fun = create_rescaling_function()\nrescale_fun\n\nShaped series: series shape does not match page shape\n\n\n(3.0865665011414225, 3.0865709219772635)\n\n\nNext, we import the TIFF file. We have 7 different z stacks, but we obivously cannot plot all of them. So for here, I am going to use the middle (z=3). Our tiff only contains two colors in the first dimension. To plot it, the colors need to be in the third dimension and we need to add a third color (RGB). We will put cellboundary in G and polyT in B and fill R with zeros.\n\nimg = tifffile.imread(\"cellpose_segmentation/full_stack.tif\")[3]\n\n\ndef make_image(img):\n    \"\"\" Function to format the np array for plotting\n    \n    Takes a np array of dimensions (2 x Y x X) and\n    formats it to Y x X x 3.\n    Third color is filled with zeros.\n    \n    \"\"\"\n    \n    # move the RGB to the third dimension\n    img = np.transpose(img, [1,2,0])\n    zeros = np.zeros(\n                [img.shape[0], img.shape[1], 1],\n                dtype = np.uint8\n            )\n    \n    # fill R(ed) with zeros\n    img = np.concatenate(\n        [zeros,img],\n        axis = 2\n    )\n    \n    # scale the colors from 0 to 255 to make it more intense\n    img[:,:,1] = np.uint8(img[:,:,1] / np.max(img[:,:,1]) * 255)\n    img[:,:,2] = np.uint8(img[:,:,2] / np.max(img[:,:,2]) * 255)\n    \n    \n    return(img)\n\nThe cell boundaries were saved as a JSON file. The file is rather big and takes long to parse. If you analyze it, you will see that is it a list of 8. One geojson file for each layer and then one for the joint polygons, we will take that. To speed things up we will only parse it once and save the joint layer in a separate file.\n\ndef import_cell_boundaries():\n    file = path+\"/segmentation_polygons_joint.shp\"\n    if os.path.exists(file):\n        print(\">>> joint polygon file already found\")\n        gdf = gpd.read_file(file)\n    else:\n        print(\">>> looking for the joint polygon layer\")\n        boundaries = geojson.load(open(path+\"/segmentation_polygons.json\"))\n        for i in range(len(boundaries)):\n            if boundaries[i].z == 'joint':\n                print(f\">>> >>> found joint polygons in layer {i}\")\n                print(f\">>> >>> saving as {file}\") \n                geom = [shape(i) for i in boundaries[2].geometries]\n                gdf = gpd.GeoDataFrame({'geometry':geom})\n                gdf.to_file(file)\n                break\n    return(gdf)\n\n\nboundaries = import_cell_boundaries()\nboundaries\n\n>>> looking for the joint polygon layer\n>>> >>> found joint polygons in layer 2\n>>> >>> saving as baysor_3_mol_per_cell//segmentation_polygons_joint.shp\n\n\n/projects/ps-yeolab5/t_cell_p01/home/mheeg/mambaforge/envs/cellpose/lib/python3.8/site-packages/geopandas/io/file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  pd.Int64Index,\n\n\n\n\n\n\n  \n    \n      \n      geometry\n    \n  \n  \n    \n      0\n      POLYGON ((133.913 1418.699, 133.580 1418.699, ...\n    \n    \n      1\n      POLYGON ((118.247 1423.365, 118.580 1423.365, ...\n    \n    \n      2\n      POLYGON ((142.580 1417.365, 142.913 1417.032, ...\n    \n    \n      3\n      POLYGON ((148.247 1412.032, 147.913 1412.032, ...\n    \n    \n      4\n      POLYGON ((150.247 1407.699, 149.913 1407.699, ...\n    \n    \n      ...\n      ...\n    \n    \n      210623\n      POLYGON ((2551.580 1585.032, 2551.247 1584.699...\n    \n    \n      210624\n      POLYGON ((1539.580 3582.032, 1539.913 3582.032...\n    \n    \n      210625\n      POLYGON ((1539.247 3584.699, 1538.913 3584.365...\n    \n    \n      210626\n      POLYGON ((3735.580 4985.365, 3735.247 4985.365...\n    \n    \n      210627\n      POLYGON ((3975.913 4916.699, 3975.913 4916.365...\n    \n  \n\n210628 rows × 1 columns\n\n\n\nThe third layer the we add is the individual transcripts.\n\ntranscripts = pd.read_csv(path+\"/segmentation.csv\")\ntranscripts\n\n\n\n\n\n  \n    \n      \n      Column1\n      Unnamed: 0\n      barcode_id\n      x\n      y\n      z\n      x_reserved\n      y_reserved\n      fov\n      gene\n      transcript_id\n      mask\n      molecule_id\n      prior_segmentation\n      confidence\n      cluster\n      cell\n      assignment_confidence\n      is_noise\n      ncv_color\n    \n  \n  \n    \n      0\n      0\n      329140\n      96\n      3822.6140\n      134.603240\n      4.0\n      206.57428\n      1246.32630\n      0\n      Pycr1\n      ENSMUST00000026133\n      0\n      1\n      0\n      0.0\n      4\n      0\n      1.0\n      True\n      #006496\n    \n    \n      1\n      1\n      425522\n      128\n      3865.5085\n      89.455734\n      5.0\n      603.74640\n      828.29380\n      0\n      Slc7a11\n      ENSMUST00000029297\n      0\n      2\n      0\n      0.0\n      1\n      0\n      1.0\n      True\n      #006395\n    \n    \n      2\n      2\n      810570\n      241\n      3972.9065\n      163.452200\n      6.0\n      1598.17210\n      1513.44620\n      0\n      Cxcr3\n      ENSMUST00000056614\n      0\n      3\n      0\n      0.0\n      7\n      0\n      1.0\n      True\n      #006293\n    \n    \n      3\n      3\n      1294999\n      381\n      3968.8958\n      33.911680\n      0.0\n      1561.03550\n      313.99704\n      0\n      Ldhb\n      ENSMUST00000130817\n      0\n      4\n      0\n      0.0\n      5\n      0\n      1.0\n      True\n      #006597\n    \n    \n      4\n      5\n      431470\n      126\n      3664.2427\n      184.795300\n      4.0\n      592.17260\n      1711.06760\n      1\n      Slc2a2\n      ENSMUST00000029240\n      0\n      5\n      0\n      0.0\n      6\n      0\n      1.0\n      True\n      #5034D5\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      16204980\n      16296383\n      891678\n      260\n      2750.3667\n      7003.081500\n      0.0\n      1390.35860\n      1875.34850\n      856\n      Ppp6r1\n      ENSMUST00000064099\n      0\n      16204981\n      0\n      0.0\n      5\n      0\n      1.0\n      True\n      #006B9B\n    \n    \n      16204981\n      16296384\n      1096165\n      316\n      2643.0085\n      6867.693000\n      1.0\n      396.30136\n      621.74725\n      856\n      Icos\n      ENSMUST00000102827\n      0\n      16204982\n      0\n      0.0\n      7\n      0\n      1.0\n      True\n      #005F8B\n    \n    \n      16204982\n      16296385\n      1337621\n      386\n      2659.0680\n      6997.968000\n      2.0\n      545.00000\n      1828.00000\n      856\n      Itga2b\n      ENSMUST00000103086\n      0\n      16204983\n      0\n      0.0\n      4\n      0\n      1.0\n      True\n      #006497\n    \n    \n      16204983\n      16296386\n      1622514\n      477\n      2635.3728\n      6870.979500\n      0.0\n      325.60034\n      652.18134\n      856\n      Hmgcs1\n      ENSMUST00000224188\n      0\n      16204984\n      0\n      0.0\n      4\n      0\n      1.0\n      True\n      #3A4E61\n    \n    \n      16204984\n      16296387\n      1622590\n      477\n      2810.0360\n      6958.539600\n      0.0\n      1942.84960\n      1462.92320\n      856\n      Hmgcs1\n      ENSMUST00000224188\n      0\n      16204985\n      0\n      0.0\n      4\n      0\n      1.0\n      True\n      #075365\n    \n  \n\n16204985 rows × 20 columns\n\n\n\nWe will also create a plot with the number of cells and the histrogam with the transcripts per cell.\n\ndef diagnostic_plots(transcripts, title):\n    fig = plt.figure(figsize = (14,4))\n    ax1 = fig.add_subplot(131)\n    ax2 = fig.add_subplot(132)\n    ax3 = fig.add_subplot(133)\n\n    # how many transcripts are assigned to a cell\n    transcript_in_cell = (transcripts.cell > 0).value_counts()\n    ax1.pie(transcript_in_cell, explode=[0.1, 0], labels=['in cell', 'not in cell'], \n           autopct='%1.1f%%',\n            startangle=90)\n    ax1.axis('equal') # to make a circle\n    ax1.set_title(f\"Transcripts assigned to cell \\n total: {np.max(transcripts.cell)} cells\")\n\n    # how many transcripts per cell\n    transcripts_per_cell = transcripts[transcripts.cell > 0].groupby(\"cell\").size()\n    ax2.hist(np.log10(transcripts_per_cell), bins=50, rwidth=0.9,color='#607c8e')\n    ax2.set_xlabel(r\"$log_{10}(Transcripts\\ per\\ cell)$\")\n    ax2.set_ylabel(r\"$cells$\")\n    ax2.set_title(\"Transcripts per cell\")\n    # np.log10(transcripts[transcripts.cell > 0].groupby(\"cell\").size()).plot.hist(grid=True, bins=50, rwidth=0.9,color='#607c8e')\n\n\n    # how many features per cell\n    features_per_cell = transcripts[transcripts.cell > 0].groupby(\"cell\")['gene'].nunique()\n    ax3.hist(features_per_cell, bins=50, rwidth=0.9,color='#607c8e')\n    ax3.set_xlabel(r\"$Features\\ per\\ cell$\")\n    ax3.set_ylabel(r\"$cells$\")\n    ax3.set_title(\"Features per cell\")\n\n    fig.tight_layout(h_pad=1.1)\n    fig.suptitle(title, fontweight =\"bold\", y=1.05)\n    fig.savefig(path+'/diagnostic_plots.jpg', dpi = 100)\n    fig.show()\n\n\ndiagnostic_plots(transcripts, path)\n\n\n\n\nNow we can put all together and create a image.\nIn order to plot the polygon, we need to transform the position to the image pixed for the polygons too. The polygons only have x and y (2d). But we can easlily create the 2d wrapper function around rescale_fun. This then can be applied to the Geopandas polygon (see the example below)\n\ndef rescale_fun_2d(x,y):\n    ones = np.ones(len(x))\n    res = rescale_fun(x,y,ones)\n    return(res[0],res[1])\n    \n\n\ntransform(rescale_fun_2d, boundaries.geometry[0])\n\n\n\n\nNow we can put all together and create a image.\n\nfig = plt.figure(figsize = (250,250))\nax = fig.add_subplot(111)\nprint(\">>> plotting image\")\nax.imshow(\n    make_image(img),\n    interpolation = \"nearest\",\n    origin='lower'\n)\nprint(\">>> plotting transcripts\")\nax.scatter(\n    rescale_fun(transcripts.x, transcripts.y, transcripts.z)[0],\n    rescale_fun(transcripts.x, transcripts.y, transcripts.z)[1],\n    s=0.05, c=transcripts.ncv_color)\nprint(\">>> plotting cell boundaries\")\nboundaries.geometry.apply(lambda x: transform(rescale_fun_2d, x)).boundary.plot(ax = ax, linewidth=0.5, edgecolor=\"red\")\n# ax.axis('off')\n# fig.tight_layout()\nprint(\">>> saving jpg\")\nfig.savefig(path+'/overlay.jpg', dpi = 100)\n\n\nfig = plt.figure(figsize = (250,250))\nax = fig.add_subplot(111)\nprint(\">>> plotting image\")\nax.imshow(\n    make_image(img),\n    interpolation = \"nearest\",\n    origin='lower'\n)\n# print(\">>> plotting transcripts\")\n# ax.scatter(transcripts.x*scales[0], transcripts.y*scales[1], s=0.01, c=transcripts.ncv_color)\nprint(\">>> plotting cell boundaries\")\nboundaries.geometry.apply(lambda x: transform(rescale_fun_2d, x)).boundary.plot(ax = ax, linewidth=0.5, edgecolor=\"white\")\nax.axis('off')\nfig.tight_layout()\nprint(\">>> saving jpg\")\nfig.savefig(path+'/overlay_no_transcripts.jpg', dpi = 100)"
  },
  {
    "objectID": "workflow/auxiliary/quantify.html",
    "href": "workflow/auxiliary/quantify.html",
    "title": "Quantification",
    "section": "",
    "text": "# # Let's set up a cluster \n# from dask_jobqueue import PBSCluster\n# cluster = PBSCluster(\n#     queue='condo',\n#     shebang='#!/bin/bash', \n#     cores=3,\n#     memory=\"80 GB\",\n#     resource_spec='nodes=1:ppn=16',\n#     walltime = \"2:00:00\"\n# )\n# cluster.scale(jobs=10)\n\n\n# from dask.distributed import Client\n# client = Client(cluster)\n# client\n\n\n# import socket\n# hostname = socket.gethostname()\n# ## getting the IP address using socket.gethostbyname() method\n# ip_address = socket.gethostbyname(hostname)\n# ## printing the hostname and ip_address\n# print(f\"Hostname: {hostname}\")\n# print(f\"IP Address: {ip_address}\")\n\n\n# from dask.distributed import Client, LocalCluster\n# cluster = LocalCluster(dashboard_address=f\"{ip_address}:8787\", host=ip_address)\n# client = Client(cluster)\n# client\n\n\n# now run all the calculations\n\n\nimport auxiliary\nimport pandas as pd\n\n\ndef quanify_auxiliary(gene, img, threshold):\n    imgs = auxiliary.read.stack(\n        name = img,\n        layers=[0,1,2,3,4,5,6], \n        verbose=True\n    )\n    tophats = auxiliary.process.tophat(imgs, size=5, verbose=True)\n    blobs = auxiliary.process.blob(\n        tophats, \n        threshold=threshold, \n        verbose=True\n    )\n    df = auxiliary.process.blobsToPandas(blobs, gene, '../MERLIN_output/pictures/micron_to_mosaic_pixel_transform.csv')\n    df.to_csv(f\"{gene}.csv\")\n\n\n# create a dict:\n# key : gene\n# value : config\n\nstains = {\n    'Fabp2': {\n        'img': \"../MERLIN_output/pictures/pyrmosaic_Fabp2_z%i.tif\",\n        'threshold': 0.05\n    },\n    'Fabp1': {\n        'img': \"../MERLIN_output/pictures/pyrmosaic_H2-Ab1_z%i.tif\",\n        'threshold': 0.05\n    },\n    'mt-Nd4l': {\n        'img': \"../MERLIN_output/pictures/pyrmosaic_Fabp1_z%i.tif\",\n        'threshold': 0.05\n    },\n    'Lyz1': {\n        'img': \"../MERLIN_output/pictures/pyrmosaic_mt-Nd4l_z%i.tif\",\n        'threshold': 0.05\n    },\n    'B2m': {\n        'img': \"../MERLIN_output/pictures/pyrmosaic_Lyz1_z%i.tif\",\n        'threshold': 0.05\n    },   \n}\n\n\n# loop through stains\nfor gene, config in stains.items():\n    quanify_auxiliary(\n        gene = gene,\n        img = config['img'],\n        threshold = config['threshold']\n    )\n\nShaped series: series shape does not match page shape\n\n\nImport file \"../MERLIN_output/pictures/pyrmosaic_Fabp2_z0.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\nImport file \"../MERLIN_output/pictures/pyrmosaic_Fabp2_z1.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\nImport file \"../MERLIN_output/pictures/pyrmosaic_Fabp2_z2.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\nImport file \"../MERLIN_output/pictures/pyrmosaic_Fabp2_z3.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\nImport file \"../MERLIN_output/pictures/pyrmosaic_Fabp2_z4.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\nImport file \"../MERLIN_output/pictures/pyrmosaic_Fabp2_z5.tif\"\n\n\nShaped series: series shape does not match page shape\n\n\nImport file \"../MERLIN_output/pictures/pyrmosaic_Fabp2_z6.tif\"\nRunning Tophat\nWorking on layer \"0\"\n[########################################] | 100% Completed | 39.7s\nWorking on layer \"1\"\n[########################################] | 100% Completed | 39.7s\nWorking on layer \"2\"\n[########################################] | 100% Completed | 39.7s\nWorking on layer \"3\"\n[########################################] | 100% Completed | 40.0s\nWorking on layer \"4\"\n[########################################] | 100% Completed | 40.0s\nWorking on layer \"5\"\n[########################################] | 100% Completed | 39.7s\nWorking on layer \"6\"\n[########################################] | 100% Completed | 39.9s\nStarting Blob detection\nWorking on layer \"0\"\n... Creating dask delayed array\n... Computing dask delayed array\n[########################################] | 100% Completed |  2min 33.2s\nWorking on layer \"1\"\n... Creating dask delayed array\n... Computing dask delayed array\n[######################################  ] | 97% Completed |  2min 27.6s"
  },
  {
    "objectID": "workflow/auxiliary/Combine_Transcripts.html",
    "href": "workflow/auxiliary/Combine_Transcripts.html",
    "title": "Combine with MerFISH",
    "section": "",
    "text": "# Combine the transcripts with the merfish transcripts\n# this will then be used for baysor\n\n\nimport polars as pl\n\n\n%time merfish = pl.read_csv(\"../MERLIN_output/detected_transcripts.csv\")\n\nCPU times: user 6.06 s, sys: 1.24 s, total: 7.3 s\nWall time: 2.33 s\n\n\n\nmerged = merfish[['global_x', 'global_y', 'global_z', 'gene']]\nmerged.shape\n\n(16296388, 4)\n\n\n\nstains = ['Fabp2',\n    'Fabp1',\n    'mt-Nd4l',\n    'Lyz1',\n    'B2m']\n\nfor gene in stains:\n    auxiliary = pl.read_csv(f\"{gene}.csv\")\n    auxiliary = auxiliary[['global_x', 'global_y', 'global_z', 'gene']]\n    merged = pl.concat([merged, auxiliary])\n\n\nmerged.shape\n\n(17812308, 4)\n\n\n\nmerged.write_csv(\"all_transcripts.csv\")"
  },
  {
    "objectID": "workflow/auxiliary/validation.html",
    "href": "workflow/auxiliary/validation.html",
    "title": "Validation",
    "section": "",
    "text": "Overlay of the MERSFISH Transcripts and the Auxiliary stain transcripts to see, that everything worked as expected…. hopefully\n\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\n\n\n# load Merfish transcripts\n# I use ploar because it is a LOT faster\n%time merfish = pl.read_csv(\"../MERLIN_output/detected_transcripts.csv\")\n\nCPU times: user 11.2 s, sys: 2.37 s, total: 13.5 s\nWall time: 4.34 s\n\n\n\nstains = ['Fabp2',\n    'Fabp1',\n    'mt-Nd4l',\n    'Lyz1',\n    'B2m']\n\n\nmerfish.shape[0]\n\n16296388\n\n\nMake an overlay plot with all stains\n\nfig, ax = plt.subplots(1, 1, figsize=(15, 15))\nax.scatter(merfish['global_x'], merfish['global_y'], s=0.01, c='gray', alpha=.2, label=f\"All Merfish transcripts ({merfish.shape[0]:,} transcripts)\")\n\nfor gene in stains:\n    auxiliary = pl.read_csv(f\"{gene}.csv\")\n    ax.scatter(auxiliary['global_x'], auxiliary['global_y'], s=0.01, label=f\"{gene} ({auxiliary.shape[0]:,} transcripts)\") \n#make points in legend bigger....\nlgnd = ax.legend(loc=\"upper right\", scatterpoints=1, fontsize=10)\nfor handle in lgnd.legendHandles:\n    handle.set_sizes([6.0])\nfig.show()\n\n\n\n\nMake individual plots for each stain\n\nfig=plt.figure(figsize=(18,12))\n\nfor (i, gene) in enumerate(stains):\n    ax = fig.add_subplot(2, 3, i+1)\n    ax.scatter(merfish['global_x'], merfish['global_y'], s=0.001, c='gray', alpha=.2, label=f\"All Merfish transcripts ({merfish.shape[0]:,} transcripts)\")\n    auxiliary = pl.read_csv(f\"{gene}.csv\")\n    ax.scatter(auxiliary['global_x'], auxiliary['global_y'], s=0.001, label=f\"{gene} ({auxiliary.shape[0]:,} transcripts)\") \n    lgnd = ax.legend(loc=\"upper right\", scatterpoints=1, fontsize=10)\n    for handle in lgnd.legendHandles:\n        handle.set_sizes([6.0])\nfig.show()"
  },
  {
    "objectID": "workflow/index.html",
    "href": "workflow/index.html",
    "title": "Workflow",
    "section": "",
    "text": "Part 1: Quanitufy auxiliary stainings\nWe will identify transcripts on the FISH images (sequential imaing rounds of the MERSCOPE run) and combine that with the MerFISH detected transcripts.\n\n\nPart 2: Cell segmentation\nOur two step approach includes cellpose and baysor.\n\nCellpose creates a segmentation based on the image data.\nBaysor then used the transcript neighboorhood to refine the segmentation.\n\nLastly, we put everything together in an Anndata object that can be used for downstream analysis."
  },
  {
    "objectID": "workflow/analysis/anndata_zarr.html",
    "href": "workflow/analysis/anndata_zarr.html",
    "title": "Anndata Zarr export",
    "section": "",
    "text": "The browser can be found here: https://merscope.heeg.io\nThe images are exported in a separate script as an ome tiff. All files are synced with a cloud storage.\nThis script also contains a few fixes to export the cell boundaries."
  },
  {
    "objectID": "workflow/analysis/anndata_zarr.html#run-magic",
    "href": "workflow/analysis/anndata_zarr.html#run-magic",
    "title": "Anndata Zarr export",
    "section": "Run Magic",
    "text": "Run Magic\n\nadata\n\nAnnData object with n_obs × n_vars = 105262 × 499\n    obs: 'x', 'y', 'cluster', 'n_transcripts', 'density', 'elongation', 'area', 'avg_confidence', 'cell_shape', 'n_genes', 'n_genes_by_counts', 'total_counts', 'leiden', 'Ucell_Main.Epithelia', 'Ucell_Main.Stroma', 'Ucell_Main.Immune', 'Ucell_Main.Endothelia', 'Ucell_Main.Neuronal', 'Ucell_CD8_Tcell', 'Ucell_CD4_Tcell', 'Ucell_Treg', 'Ucell_NK_Tcell', 'Ucell_TRM_CD8_Tcell', 'Ucell_TCM_CD8_Tcell', 'Ucell_ILC', 'Ucell_TEM_Tcell', 'Ucell_TE_Tcell', 'Ucell_P14', 'Ucell_B_cell', 'Ucell_cDC1', 'Ucell_Neutrophil', 'Ucell_Macrophage', 'Ucell_TA', 'Ucell_Enterocyte_low', 'Ucell_Enterocyte_med', 'Ucell_Enterocyte_high', 'Ucell_Enterocyte_tip', 'Ucell_Endothelia', 'Ucell_ISC', 'Ucell_Paneth', 'Ucell_Goblet', 'Ucell_Tuft', 'Ucell_Enteroendocrine', 'Ucell_Ncam1+_fibroblasts', 'Ucell_Fibroblast_progenitor', 'Ucell_Pdgfra+_fibroblasts', 'Ucell_Acta2+_fibroblasts', 'Ucell_Pdgfrb+_fibroblasts', 'Ucell_Proliferating', 'Ucell_Lymphatic', 'Ucell_Astrocytes', 'Ucell_Neuron', 'Ucell_Microglia', 'celltype'\n    var: 'n_cells', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'means', 'variances', 'residual_variances', 'highly_variable_rank', 'highly_variable'\n    uns: 'celltype_colors', 'dendrogram_leiden', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'pearson_residuals_normalization', 'points', 'umap'\n    obsm: 'X_pca', 'X_umap', 'spatial', 'unrolled'\n    varm: 'PCs'\n    layers: 'raw', 'sqrt_norm'\n    obsp: 'connectivities', 'distances'\n\n\n\nadata.X\n\narray([[-0.18696232, -0.4049479 ,  0.24218531, ..., -0.44860196,\n        -0.3415596 , -1.6352955 ],\n       [-0.16935983, -0.36686456, -0.7998022 , ..., -0.24956763,\n        -0.30942446, -0.8262355 ],\n       [-0.16461276,  2.444168  , -0.77751535, ..., -1.095034  ,\n        -0.300757  , -1.4441031 ],\n       ...,\n       [-0.03107334, -0.06734505, -0.14717919, ..., -0.207884  ,\n        -0.05679015, -0.27534527],\n       [-0.02491414, -0.0539966 , -0.11801044, ..., -0.16669086,\n        -0.04553368, -0.22079724],\n       [-0.01856993, -0.04024696, -0.08796251, ...,  7.9226847 ,\n        -0.03393896, -0.16459039]], dtype=float32)\n\n\n\nsc.pl.violin(adata=adata, keys=['Acta2', 'Cd8a'], groupby='celltype', use_raw=False)\n\n\n\n\n\nsc.external.pp.magic(adata, name_list='all_genes', n_jobs=12, verbose=True)\n\nCalculating MAGIC...\n  Running MAGIC on 105262 cells and 499 genes.\n  Calculating graph and diffusion operator...\n    Calculating PCA...\n    Calculated PCA in 4.83 seconds.\n    Calculating KNN search...\n    Calculated KNN search in 367.73 seconds.\n    Calculating affinities...\n    Calculated affinities in 366.41 seconds.\n  Calculated graph and diffusion operator in 739.08 seconds.\n  Calculating imputation...\n  Calculated imputation in 5.58 seconds.\nCalculated MAGIC in 744.78 seconds.\n\n\n/home/max/QnapSync/Documents/Postdoc/Lab/Projects/Merscope/Slide01_Doudenum/.venv/lib/python3.10/site-packages/magic/utils.py:145: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n  data = anndata.AnnData(data)\n\n\n\nadata.raw.X\n\narray([[-0.18696232, -0.4049479 ,  0.24218531, ..., -0.44860196,\n        -0.3415596 , -1.6352955 ],\n       [-0.16935983, -0.36686456, -0.7998022 , ..., -0.24956763,\n        -0.30942446, -0.8262355 ],\n       [-0.16461276,  2.444168  , -0.77751535, ..., -1.095034  ,\n        -0.300757  , -1.4441031 ],\n       ...,\n       [-0.03107334, -0.06734505, -0.14717919, ..., -0.207884  ,\n        -0.05679015, -0.27534527],\n       [-0.02491414, -0.0539966 , -0.11801044, ..., -0.16669086,\n        -0.04553368, -0.22079724],\n       [-0.01856993, -0.04024696, -0.08796251, ...,  7.9226847 ,\n        -0.03393896, -0.16459039]], dtype=float32)\n\n\n\nsc.pl.violin(adata=adata, keys=['Acta2', 'Cd8a', 'Hic1'], groupby='celltype')\n\n\n\n\n\nsc.pl.violin(adata=adata, keys=['Acta2', 'Cd8a', 'Hic1'], groupby='celltype', use_raw=False)\n\n\n\n\n\nadata = adata\n\n\nscale = 3.08657      \n\n\n# apply the scale\n# and round to two decimals to make the file a little smaller (saves ~250MB)\nadata.uns['points'].groupby('gene').apply(lambda x: (x[['x', 'y']].to_numpy()*scale).round(2)).to_json('/home/max/Desktop/vitesse/data/json/molecules.json')\n\n\nimport zarr\n\n\nadata.obs['leiden'] = adata.obs.leiden.astype('int32')\n\n\n# adata.obs = adata.obs.rename(columns={\"cell type\": \"cell_type\"})\n# adata.obs['cell_type'] = adata.obs['cell_type'].astype('S16')\n\n\ngpd.GeoSeries.from_wkt(np.array(adata.obs.cell_shape))\n\n0         POLYGON ((121.907 1410.945, 125.958 1414.014, ...\n1         POLYGON ((119.717 1412.486, 118.002 1416.133, ...\n2         POLYGON ((145.004 1410.353, 145.535 1406.199, ...\n3         POLYGON ((143.044 1401.912, 142.227 1402.037, ...\n4         POLYGON ((141.254 1406.968, 140.953 1407.200, ...\n                                ...                        \n105257    POLYGON ((5592.448 3571.183, 5591.485 3570.595...\n105258    POLYGON ((3875.762 3385.923, 3875.093 3384.950...\n105259    POLYGON ((1189.708 5137.589, 1190.759 5135.508...\n105260    POLYGON ((3923.678 6011.807, 3922.497 6012.943...\n105261    POLYGON ((3021.903 4097.709, 3022.185 4096.938...\nLength: 105262, dtype: geometry\n\n\n\nimport geopandas as gpd\nfrom shapely.geometry import Polygon, mapping\ntest = gpd.GeoSeries.from_wkt(np.array(adata.obs.cell_shape)).apply(lambda x: np.array(mapping(x)['coordinates'])[0].astype('float32'))\n\nTypeError: Non geometry data passed to GeoSeries constructor, received data of dtype 'category'\n\n\n\ntest\n\n\nadata.uns['poly'] = [np.resize(t, (24,2))*scale for t in test]\n#adata.uns['poly'] = test\n\n\nadata.uns['poly'] =  adata.uns['poly'].copy()\n\n\nadata.obsm['spatial'] = adata.obsm['spatial']*scale\nadata.obsm['spatial'] = adata.obsm['spatial'].copy()\n\n\nadata = adata.copy()\n\n\ndims = [p.shape[0] for p in adata.uns['poly']]\n[d for d in dims if d < 5]\n\n\nadata.write_zarr('/home/max/Desktop/vitesse/data/merscope.zarr', [adata.shape[0], 10])\n\n\nadata.obsm['spatial'][1362]"
  },
  {
    "objectID": "workflow/analysis/image_ome.html",
    "href": "workflow/analysis/image_ome.html",
    "title": "Image OME-TIFF export",
    "section": "",
    "text": "import zarr\nimport os\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport skimage.io\nfrom PIL import Image\nfrom skimage.transform import rescale\nfrom ome_zarr.io import parse_url\nfrom ome_zarr.writer import write_image\nfrom skimage import util\n\n\nimg = skimage.io.imread(f\"../01_cell_segmentation/full_stack_vitessce.tif\")\n\n\nimg.shape\n\n(5, 21673, 19821)\n\n\n\nscale = 3.0865\n#img = img[:, ::2, ::2]\n\n#img = rescale(img, 1/(scale/2), channel_axis=0)\n\n\nimg\n\narray([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]],\n\n       [[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]],\n\n       [[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]],\n\n       [[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]],\n\n       [[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)\n\n\n\nimg.shape\n\n(5, 21673, 19821)\n\n\n\ndefault_window = {\n      \"start\": 0,\n      \"min\": 0,\n      \"max\": 256,\n      \"end\": 100\n}\n\n\npath = \"/home/max/Desktop/vitesse/data/image.ome.zarr\"\nif os.path.exists(path) and os.path.isdir(path):\n    shutil.rmtree(path)\nos.mkdir(path)\nstore = parse_url(path, mode=\"w\").store\nroot = zarr.group(store=store)\nwrite_image(image=img, group=root, axes=\"cyx\", storage_options=dict(chunks=(1, 1024, 1024)))\n# optional rendering settings\nroot.attrs[\"omero\"] = {\n    \"id\": 1,\n    \"name\": 'Images',\n    \"version\": 0.01,\n    \"rdefs\": {\n    },      \n    \"channels\": [\n        {\n            \"active\": False,\n            \"coefficient\": 1.0,\n            \"color\": \"88FF00\",\n            \"family\": \"linear\",\n            \"inverted\": False,\n            \"label\": \"Cellboundary 1\",\n            \"window\": default_window\n        },\n        {\n            \"active\": True,\n            \"coefficient\": 1.0,\n            \"color\": \"FFFF00\",\n            \"family\": \"linear\",\n            \"inverted\": False,\n            \"label\": \"Cellboundary 2\",\n            \"window\": default_window\n        },\n        {\n            \"active\": False,\n            \"coefficient\": 1.0,\n            \"color\": \"AE21FF\",\n            \"family\": \"linear\",\n            \"inverted\": False,\n            \"label\": \"Cellboundary 3\",\n            \"window\": default_window\n        },\n        {\n            \"active\": True,\n            \"coefficient\": 1.0,\n            \"color\": \"0000FF\",\n            \"family\": \"linear\",\n            \"inverted\": False,\n            \"label\": \"poly T\",\n            \"window\": default_window\n        },\n        {\n            \"active\": False,\n            \"coefficient\": 1.0,\n            \"color\": \"0000FF\",\n            \"family\": \"linear\",\n            \"inverted\": False,\n            \"label\": \"DAPI\",\n            \"window\": default_window\n        }\n    ],\n}\n\nFor some reason, the .zattrs files needs to be adapted:\n“axes”: [ “c”, “y”, “x” ],"
  },
  {
    "objectID": "workflow/analysis/qc.html",
    "href": "workflow/analysis/qc.html",
    "title": "QC",
    "section": "",
    "text": "import scanpy as sc\nimport anndata as ad\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\nsc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.figdir = \"./figures/preprocessing/\"\nsc.set_figure_params(dpi=80, dpi_save=300, frameon=True, vector_friendly=True, figsize=[8,5])"
  },
  {
    "objectID": "workflow/analysis/qc.html#qc",
    "href": "workflow/analysis/qc.html#qc",
    "title": "QC",
    "section": "QC",
    "text": "QC\nIn this section, let’s perform some QC metrics. Let’s start by removing cells that have less than 5 genes and genes that are expressed in less that 3 cells/\n\nadata.var_names_make_unique()\nprint(\"data shape:\", adata.shape)\nsc.pp.filter_cells(adata, min_genes=5)\nsc.pp.filter_genes(adata, min_cells=3)\n\ndata shape: (120694, 499)\nfiltered out 6818 cells that have less than 5 genes expressed\n\n\n\nsc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)\nadata\n\nAnnData object with n_obs × n_vars = 113876 × 499\n    obs: 'x', 'y', 'cluster', 'n_transcripts', 'density', 'elongation', 'area', 'avg_confidence', 'cell_shape', 'n_genes', 'n_genes_by_counts', 'total_counts'\n    var: 'n_cells', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'\n    uns: 'points'\n    obsm: 'spatial', 'unrolled'\n\n\nNext, we can use the metrics provided by Baysor and the newly calculated values. - ‘n_transcripts’, ‘density’, ‘elongation’, ‘area’, ‘avg_confidence’ from baysor - n_genes, n_genes_by_counts and total counts In a first step, we check if those are NAN values\n\nfor metric in ['n_transcripts', 'density', 'elongation', 'area', 'avg_confidence', 'n_genes', 'n_genes_by_counts', 'total_counts']:\n    x = adata.obs[metric]\n    print(f\"{metric} has  {np.count_nonzero(np.isnan(x))} NAN values and {np.count_nonzero(np.isinf(x))} inf values\")\n\nn_transcripts has  0 NAN values and 0 inf values\ndensity has  0 NAN values and 1 inf values\nelongation has  0 NAN values and 1 inf values\narea has  0 NAN values and 0 inf values\navg_confidence has  0 NAN values and 0 inf values\nn_genes has  0 NAN values and 0 inf values\nn_genes_by_counts has  0 NAN values and 0 inf values\ntotal_counts has  0 NAN values and 0 inf values\n\n\nThere is only one cell with a inf density value. Let’s remove that too\n\nfor metric in ['n_transcripts', 'density', 'elongation', 'area', 'avg_confidence', 'n_genes', 'n_genes_by_counts', 'total_counts']:\n    x = adata.obs[metric]\n    print(x.index[np.where(np.isinf(x))])\n\nIndex([], dtype='object', name='cell')\nIndex(['17571'], dtype='object', name='cell')\nIndex(['17571'], dtype='object', name='cell')\nIndex([], dtype='object', name='cell')\nIndex([], dtype='object', name='cell')\nIndex([], dtype='object', name='cell')\nIndex([], dtype='object', name='cell')\nIndex([], dtype='object', name='cell')\n\n\n\nadata = adata[~(adata.obs.index == '17571')]\n\n\nsc.pl.violin(\n    adata, \n    ['n_transcripts', 'density', 'elongation', 'area', 'avg_confidence', 'n_genes', 'n_genes_by_counts', 'total_counts'],\n    stripplot=False,\n    multi_panel=True, \n    save=\"_genes_counts.png\", \n    jitter=0.4\n)\n\nWARNING: saving figure to file figures/preprocessing/violin_genes_counts.png\n\n\n\n\n\nTo filter the cells, let’s use an approach similar to https://rdrr.io/github/LTLA/scuttle/man/perCellQCFilters.html. For each metric, we try to detect outliers based on the median and MAD deviations as defined in the config. The scripts creates plots with the upper and lower boundaries and creates a mask that we can then use for subsetting the adata object\n\nmetrics = {\n    'n_transcripts' : {\n        'n_mad': 3,\n        'log': True\n    },\n    'density' :{\n        'n_mad': 4,\n        'log': True\n    }, \n    'elongation' :{\n        'n_mad': 5,\n        'log': True\n    },\n    'area' :{\n        'n_mad': 5,\n        'log': False\n    },\n    'avg_confidence' :{\n        'n_mad': 20,\n        'log': False\n    },\n    'n_genes' :{\n        'n_mad': 5,\n        'log': False\n    }, \n    'n_genes_by_counts' :{\n        'n_mad': 5,\n        'log': False\n    },\n    'total_counts' :{\n        'n_mad': 3,\n        'log': True\n    },\n    }\nfig = plt.figure(figsize=(15, 12))\nsummary_discard = []\nfor i, metric in enumerate(metrics):\n    settings = metrics[metric]\n    x = np.array(adata.obs[metric])\n    if settings['log']: \n        x = np.log10(x)\n    median = np.median(x)\n    mad = stats.median_abs_deviation(x)\n    n_mad = settings['n_mad']\n    keep = (x >= median - mad*n_mad) & (x<= median + mad*n_mad)\n    summary_discard.append(~keep)\n    ax = plt.subplot(3, 3, i + 1)\n    sns.violinplot(x, ax=ax)\n    ax.set_title(metric)\n    ax.axhline(median)\n    ax.axhline(median+mad*n_mad)\n    ax.axhline(median-mad*n_mad)\n    ax.text(x=0.1, y=0.7, s=f\"Remove {np.sum(~keep)} cell\\n({np.sum(~keep)/len(keep)*100:.2f} %)\", transform=ax.transAxes)\n\n\n\n\n\nsummary_discard = np.vstack(summary_discard)\ndiscard = np.sum(summary_discard, axis=0) > 0\nnp.sum(discard)\n\n8613\n\n\nSo in total, we will get rid of 8613 cells. This seems reasonable\n\nadata = adata[~discard]\nadata\n\nView of AnnData object with n_obs × n_vars = 105262 × 499\n    obs: 'x', 'y', 'cluster', 'n_transcripts', 'density', 'elongation', 'area', 'avg_confidence', 'cell_shape', 'n_genes', 'n_genes_by_counts', 'total_counts'\n    var: 'n_cells', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'\n    uns: 'points'\n    obsm: 'spatial', 'unrolled'\n\n\n\nadata.write(\"anndata_after_qc.h5ad\")"
  },
  {
    "objectID": "workflow/analysis/umap.html",
    "href": "workflow/analysis/umap.html",
    "title": "Annotation",
    "section": "",
    "text": "import scanpy as sc\nimport anndata as ad\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport swifter\n\nsc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\nsc.settings.figdir = \"./figures/umap/\"\nsc.set_figure_params(dpi=80, dpi_save=300, frameon=True, vector_friendly=True, figsize=[8,5])\n\n\nadata = ad.read_h5ad(\"anndata_after_qc.h5ad\")\nadata\n\nAnnData object with n_obs × n_vars = 105262 × 499\n    obs: 'x', 'y', 'cluster', 'n_transcripts', 'density', 'elongation', 'area', 'avg_confidence', 'cell_shape', 'n_genes', 'n_genes_by_counts', 'total_counts'\n    var: 'n_cells', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'\n    uns: 'points'\n    obsm: 'spatial', 'unrolled'\n\n\n\nmarkers = [\n    \"Xist\",\n    \"Epcam\"\n]\n\n\nsc.experimental.pp.highly_variable_genes(\n        adata, flavor=\"pearson_residuals\", n_top_genes=2000\n)\n\nextracting highly variable genes\n--> added\n    'highly_variable', boolean vector (adata.var)\n    'highly_variable_rank', float vector (adata.var)\n    'highly_variable_nbatches', int vector (adata.var)\n    'highly_variable_intersection', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'variances', float vector (adata.var)\n    'residual_variances', float vector (adata.var)\n\n\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\nhvgs = adata.var[\"highly_variable\"]\nax.scatter(\n    adata.var[\"mean_counts\"], adata.var[\"residual_variances\"], s=3, edgecolor=\"none\"\n)\nax.scatter(\n    adata.var[\"mean_counts\"][hvgs],\n    adata.var[\"residual_variances\"][hvgs],\n    c=\"tab:red\",\n    label=\"selected genes\",\n    s=3,\n    edgecolor=\"none\",\n)\nax.scatter(\n    adata.var[\"mean_counts\"][np.isin(adata.var_names, markers)],\n    adata.var[\"residual_variances\"][np.isin(adata.var_names, markers)],\n    c=\"k\",\n    label=\"known marker genes\",\n    s=50,\n    edgecolor=\"none\",\n)\nax.set_xscale(\"log\")\nax.set_xlabel(\"mean expression\")\nax.set_yscale(\"log\")\nax.set_ylabel(\"residual variance\")\n\nax.spines[\"right\"].set_visible(False)\nax.spines[\"top\"].set_visible(False)\nax.yaxis.set_ticks_position(\"left\")\nax.xaxis.set_ticks_position(\"bottom\")\nplt.legend(loc='upper left')\n\n<matplotlib.legend.Legend at 0x7f172df60d00>\n\n\n\n\n\n\n#keep raw and depth-normalized counts for later\nadata.layers[\"raw\"] = adata.X.copy()\nadata.layers[\"sqrt_norm\"] = np.sqrt(\n    sc.pp.normalize_total(adata, inplace=False)[\"X\"]\n)\n\nnormalizing counts per cell\n    finished (0:00:00)\n\n\n\nsc.experimental.pp.normalize_pearson_residuals(adata)\n\ncomputing analytic Pearson residuals on adata.X\n    finished (0:00:00)\n\n\n\nsc.pp.pca(adata, n_comps=30)\n\ncomputing PCA\n    on highly variable genes\n    with n_comps=30\n    finished (0:00:02)\n\n\n\nsc.pp.neighbors(adata, n_neighbors=30, n_pcs=30, metric='correlation')\n\ncomputing neighbors\n    using 'X_pca' with n_pcs = 30\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:29)\n\n\n\nsc.tl.umap(adata, min_dist=0.3)\n\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:01:01)\n\n\n\nsc.tl.leiden(adata)\n\nrunning Leiden clustering\n    finished: found 32 clusters and added\n    'leiden', the cluster labels (adata.obs, categorical) (0:00:57)\n\n\n\nAnnotation\n\nimport csv\nwith open('Ucell_celltypes_v1.csv', \"r\") as f:\n    reader = csv.reader(f)\n    marker_genes_dict = {}\n\n    for row in reader:\n        key = row[0]\n        # this removes the empty values\n        marker_genes_dict[key] = [i for i in row[1:] if i]\n\n\nall_marker_genes = np.concatenate([*marker_genes_dict.values()])\nall_marker_genes = [i.strip(r\"\\+|\\-\") for i in all_marker_genes]\nall_marker_genes = np.unique(all_marker_genes)\nall_marker_genes = np.append(all_marker_genes, 'leiden')\n\n\ndef ceiling_division(numerator, denominator):\n    return -(-numerator // denominator)\n\nncol = 7\nnrow = ceiling_division(len(all_marker_genes),ncol)\n\nfig = plt.figure(figsize=(4*ncol, 3*nrow))\nfig.tight_layout()\nfor i, m in enumerate(all_marker_genes):\n    ax = plt.subplot(nrow, ncol, i+1)\n    sc.pl.umap(adata, color=m, layer=\"sqrt_norm\", ax=ax, show=False)\n    ax.set(xlabel=None)\n    ax.set(ylabel=None)\nfig.savefig(\"./figures/umap/Marker_genes.png\", bbox_inches='tight')\n\n/home/max/QnapSync/Documents/Postdoc/Lab/Projects/Merscope/Slide01_Doudenum/.venv/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter(\n\n\n\n\n\nLet’s create our own U Cell implementation\n\ndef create_rankings(ex_mtx: pd.DataFrame, seed=None) -> pd.DataFrame:\n    \"\"\"\n    Create a rankings dataframe from a single cell expression profile dataframe.\n    :param ex_mtx: The expression profile matrix. The rows should correspond to different cells, the columns to different\n        genes (n_cells x n_genes).\n    :return: A genome rankings dataframe (n_cells x n_genes).\n    \"\"\"\n\n    return (\n        ex_mtx.sample(frac=1.0, replace=False, axis=1, random_state=seed)\n        .rank(axis=1, ascending=False, method=\"first\", na_option=\"bottom\")\n        .astype('uint32')\n    )\n\ndef u_stat(ranks, maxRank=100):\n    ranks = ranks.copy()\n    ranks[ranks > maxRank] = maxRank+1\n    rank_sum = ranks.sum(axis =1) \n    len_sig = len(ranks.columns)\n    if len_sig==0:\n        return 0\n    u_value = rank_sum - (len_sig * (len_sig + 1))/2\n    auc = 1 - u_value/(len_sig * maxRank)\n    return(auc)\n\n\ndef _calc_score(m, signature):\n    sig_neg = [m.strip(r\"\\+|\\-\") for m in signature if m.endswith(\"-\")]\n    sig_pos = [m.strip(r\"\\+|\\-\") for m in signature if not m.endswith(\"-\")]\n\n    return(u_stat(ranks = m[sig_pos]) - u_stat(ranks = m[sig_neg]))\n\ndef calc_scores(adata, marker_genes_dict):\n    m = pd.DataFrame(adata.layers['sqrt_norm'], columns=adata.var_names)\n    m = create_rankings(pd.DataFrame(m), seed=42)\n\n    scores = {}\n    for k, v in marker_genes_dict.items():\n        scores[\"Ucell_\"+k] = _calc_score(m, v)\n\n    scores = pd.DataFrame(scores)\n    scores[scores < 0] = 0\n    return(scores)\n\nscores = calc_scores(adata, marker_genes_dict)\n\n\nscores\n\n\n\n\n\n  \n    \n      \n      Ucell_Main.Epithelia\n      Ucell_Main.Stroma\n      Ucell_Main.Immune\n      Ucell_Main.Endothelia\n      Ucell_Main.Neuronal\n      Ucell_CD8_Tcell\n      Ucell_CD4_Tcell\n      Ucell_Treg\n      Ucell_NK_Tcell\n      Ucell_TRM_CD8_Tcell\n      ...\n      Ucell_Ncam1+_fibroblasts\n      Ucell_Fibroblast_progenitor\n      Ucell_Pdgfra+_fibroblasts\n      Ucell_Acta2+_fibroblasts\n      Ucell_Pdgfrb+_fibroblasts\n      Ucell_Proliferating\n      Ucell_Lymphatic\n      Ucell_Astrocytes\n      Ucell_Neuron\n      Ucell_Microglia\n    \n  \n  \n    \n      0\n      0.945000\n      0.0\n      0.131667\n      0.00\n      0.0\n      0.020\n      0.0100\n      0.010\n      0.0\n      0.035625\n      ...\n      0.000000\n      0.000000\n      0.0\n      0.0\n      0.000\n      0.01\n      0.0\n      0.0150\n      0.0\n      0.005\n    \n    \n      1\n      0.804167\n      0.0\n      0.000000\n      0.04\n      0.0\n      0.034\n      0.0000\n      0.125\n      0.0\n      0.147500\n      ...\n      0.000000\n      0.000000\n      0.0\n      0.0\n      0.000\n      0.01\n      0.0\n      0.0150\n      0.0\n      0.275\n    \n    \n      2\n      0.788333\n      0.0\n      0.096667\n      0.03\n      0.0\n      0.030\n      0.0000\n      0.000\n      0.0\n      0.145000\n      ...\n      0.000000\n      0.000000\n      0.0\n      0.0\n      0.000\n      0.01\n      0.0\n      0.0150\n      0.0\n      0.005\n    \n    \n      3\n      0.755000\n      0.0\n      0.186667\n      0.27\n      0.0\n      0.270\n      0.1125\n      0.050\n      0.0\n      0.181250\n      ...\n      0.000000\n      0.000000\n      0.0\n      0.0\n      0.000\n      0.01\n      0.0\n      0.0150\n      0.0\n      0.005\n    \n    \n      4\n      0.305000\n      0.0\n      0.131667\n      0.66\n      0.0\n      0.122\n      0.0000\n      0.000\n      0.0\n      0.236250\n      ...\n      0.203333\n      0.039286\n      0.0\n      0.0\n      0.005\n      0.01\n      0.0\n      0.0150\n      0.0\n      0.005\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      105257\n      0.000000\n      0.0\n      0.131667\n      0.66\n      0.0\n      0.132\n      0.0000\n      0.000\n      0.0\n      0.236250\n      ...\n      0.203333\n      0.037857\n      0.0\n      0.0\n      0.005\n      0.01\n      0.0\n      0.0150\n      0.0\n      0.005\n    \n    \n      105258\n      0.000000\n      0.0\n      0.131667\n      0.66\n      0.0\n      0.112\n      0.0000\n      0.000\n      0.0\n      0.297500\n      ...\n      0.203333\n      0.040714\n      0.0\n      0.0\n      0.005\n      0.01\n      0.0\n      0.0175\n      0.0\n      0.005\n    \n    \n      105259\n      0.321667\n      0.0\n      0.275000\n      0.62\n      0.0\n      0.146\n      0.0000\n      0.000\n      0.0\n      0.226250\n      ...\n      0.000000\n      0.000000\n      0.0\n      0.0\n      0.000\n      0.01\n      0.0\n      0.0150\n      0.0\n      0.005\n    \n    \n      105260\n      0.941667\n      0.0\n      0.131667\n      0.66\n      0.0\n      0.122\n      0.0000\n      0.000\n      0.0\n      0.235625\n      ...\n      0.000000\n      0.000000\n      0.0\n      0.0\n      0.000\n      0.01\n      0.0\n      0.0175\n      0.0\n      0.005\n    \n    \n      105261\n      0.000000\n      0.0\n      0.136667\n      0.69\n      0.0\n      0.114\n      0.0000\n      0.000\n      0.0\n      0.243750\n      ...\n      0.213333\n      0.042143\n      0.0\n      0.0\n      0.005\n      0.01\n      0.0\n      0.0200\n      0.0\n      0.010\n    \n  \n\n105262 rows × 40 columns\n\n\n\n\nscores.index = adata.obs.index\nadata.obs = pd.concat([adata.obs, scores], axis=1)\n\n\nk = marker_genes_dict.keys()\nncol = 5\nnrow = ceiling_division(len(k),ncol)\n\nfig = plt.figure(figsize=(5*ncol, 4*nrow))\nfig.tight_layout()\nfor i, m in enumerate(k):\n    ax = plt.subplot(nrow, ncol, i+1)\n    sc.pl.umap(adata, color=\"Ucell_\"+m, ax=ax, show=False)\n    ax.set(xlabel=None)\n    ax.set(ylabel=None)\nfig.savefig(\"./figures/umap/UCell_scores.png\", bbox_inches='tight')\n\n\n\n\n\nk = marker_genes_dict.keys()\nncol = 3\nnrow = ceiling_division(len(k),ncol)\n\nfig = plt.figure(figsize=(12*ncol, 4*nrow))\nfig.tight_layout()\nfor i, m in enumerate(k):\n    ax = plt.subplot(nrow, ncol, i+1)\n    sc.pl.violin(adata, keys=\"Ucell_\"+m, groupby='leiden',ax=ax, show=False,  stripplot=False)\n    ax.set(xlabel=None)\n    ax.set(ylabel=None)\n    ax.set(title=m)\nfig.savefig(\"./figures/umap/Violin_scores.png\", bbox_inches='tight')\n\n\n\n\n\nsc.pl.matrixplot(adata, [\"Ucell_\"+m for m in k], 'leiden', dendrogram=True, cmap='Blues', standard_scale='var', colorbar_title='column scaled\\nexpression')\n\nWARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n    using 'X_pca' with n_pcs = 30\nStoring dendrogram info using `.uns['dendrogram_leiden']`\n\n\n\n\n\n\nwith plt.rc_context({\"figure.figsize\": (6, 5), \"figure.dpi\": (600)}):\n    sc.pl.umap(adata, color='leiden', save=\"_leiden.png\", legend_loc=\"on data\", legend_fontoutline=1)\n\nwith plt.rc_context({\"figure.figsize\": (6, 5), \"figure.dpi\": (600)}):\n    sc.pl.umap(adata, color='leiden', save=\"_leiden2.png\")\n\nWARNING: saving figure to file figures/umap/umap_leiden.png\n\n\n/home/max/QnapSync/Documents/Postdoc/Lab/Projects/Merscope/Slide01_Doudenum/.venv/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter(\n\n\n\n\n\nWARNING: saving figure to file figures/umap/umap_leiden2.png\n\n\n/home/max/QnapSync/Documents/Postdoc/Lab/Projects/Merscope/Slide01_Doudenum/.venv/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter(\n\n\n\n\n\n\ndef unique_genes(gene_list):\n    genes = [g for genes in gene_list.values() for g in genes]\n    genes = [m.strip(r\"\\+|\\-\") for m in genes if not m.endswith(\"+-\")]\n    genes = np.unique(genes)\n    return(genes)\nsc.pl.matrixplot(adata, unique_genes(marker_genes_dict), 'leiden', dendrogram=True, cmap='Blues', standard_scale='var', colorbar_title='column scaled\\nexpression')\n\n\n\n\n\n\ncluster_to_celltype = {\n    0: \"Enterocyte, bottom\",\n    1: \"Enterocyte\",\n    2: \"Enterocyte\",\n    3: \"Enterocyte\",\n    4: \"Enterocyte\",\n    5: \"Enterocyte\",\n    6: \"Goblet\",\n    7: \"Enterocyte\",\n    8: \"CD8 P14\",\n    9: \"Enterocyte\",\n    10: \"other immune\",\n\n    11: \"Fibroblast, Acta2\",\n    12: \"Fibroblast\",\n    13: \"Endothel\",\n    14: \"Enterocyte\",\n    15: \"CD8\",\n    16: \"Fibroblast\",\n    17: \"Enterocyte, tip\",\n    18: \"Enteroendocrine\",\n    19: \"Tuft\",\n    20: \"B cells and DC\",\n    21: \"Fibroblast\",\n\n    22: \"Fibroblast\",\n    23: \"Fibroblast\",\n    24: \"Endothel\",\n    25: \"Goblet\",\n    26: \"CD4\",\n    27: \"Enterocyte\",\n    28: \"Fibroblast\",\n    29: \"Paneth\",\n    30: \"NK\",\n    31: \"Intestinal stem cells\",\n}\n\nadata.obs['celltype'] = adata.obs['leiden'].astype('int').map(cluster_to_celltype).astype(\"category\")\n\n\nadata.obs['celltype']\n\ncell\n1         Enterocyte, tip\n2         Enterocyte, tip\n3         Enterocyte, tip\n4         Enterocyte, tip\n5         Enterocyte, tip\n               ...       \n120618         Enterocyte\n120619            CD8 P14\n120626               Tuft\n120630         Enterocyte\n120631         Enterocyte\nName: celltype, Length: 105262, dtype: category\nCategories (17, object): ['B cells and DC', 'CD4', 'CD8', 'CD8 P14', ..., 'NK', 'Paneth', 'Tuft', 'other immune']\n\n\n\nsc.pl.umap(adata, color='celltype')\n\n\n\n\n\nadata.write(\"anndata_annotated.h5ad\")"
  },
  {
    "objectID": "workflow/analysis/index.html",
    "href": "workflow/analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "QC\n\n\n\n\n\nPerform QC of the spatial dataset. Exclude low quality or un-plausible cells.\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\n\n\nAnnotation\n\n\n\n\n\nPerform Normalization, Dimensional reduction and annotate the cells\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\n\n\nAnndata Zarr export\n\n\n\n\n\nRun MAGIC and export the anndata in the zarr format for the Vitessce browser\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\n\n\nImage OME-TIFF export\n\n\n\n\n\nExport the images for the Vitessce browser\n\n\n\n\n\n\nFeb 18, 2023\n\n\nMaximilian Heeg\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "contribute.html",
    "href": "contribute.html",
    "title": "Contribute",
    "section": "",
    "text": "Clone the repository, add a protocol in markdown format and push it. The website in build automatically after every push. The link to the github repo is github.com/maximilian-heeg/spatial-workflow.\nIf you see a mistake, you can modify the current site my clicking on Edit this page on the right side of each site.\nThe website is generated using quarto. See their website to learn more about the structure of the webpage."
  },
  {
    "objectID": "contribute.html#via-mail",
    "href": "contribute.html#via-mail",
    "title": "Contribute",
    "section": "Via Mail",
    "text": "Via Mail\nYou can always send me a protocol as markdown, word, etc and I will try to include it here."
  }
]